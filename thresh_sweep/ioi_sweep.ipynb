{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6606875e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/canrager/.pyenv/versions/acdc_env/envs/acdcpp_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../Automatic-Circuit-Discovery/')\n",
    "sys.path.append('../tracr/')\n",
    "sys.path.append('..')\n",
    "import re\n",
    "\n",
    "import acdc\n",
    "from acdc.TLACDCExperiment import TLACDCExperiment\n",
    "from acdc.acdc_utils import TorchIndex, EdgeType\n",
    "import numpy as np\n",
    "import torch as t\n",
    "from torch import Tensor\n",
    "import einops\n",
    "import itertools\n",
    "\n",
    "from transformer_lens import HookedTransformer, ActivationCache\n",
    "\n",
    "import tqdm.notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from rich import print as rprint\n",
    "from rich.table import Table\n",
    "\n",
    "from jaxtyping import Float, Bool\n",
    "from typing import Callable, Tuple, Union, Dict, Optional\n",
    "\n",
    "from utils.prune_utils import get_3_caches, split_layers_and_heads\n",
    "from ACDCPPExperiment import ACDCPPExperiment\n",
    "\n",
    "device = t.device('cuda') if t.cuda.is_available() else t.device('cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a16eab",
   "metadata": {},
   "source": [
    "# Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20df2bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\n",
    "    'gpt2-small',\n",
    "    center_writing_weights=False,\n",
    "    center_unembed=False,\n",
    "    fold_ln=False,\n",
    "    device=device,\n",
    ")\n",
    "model.set_use_hook_mlp_in(True)\n",
    "model.set_use_split_qkv_input(True)\n",
    "model.set_use_attn_result(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf38f0b5",
   "metadata": {},
   "source": [
    "from acdc.ioi.utils import get_ioi_true_edges\n",
    "ioi_true_edges = get_ioi_true_edges(model)\n",
    "for (b1, i1, b2, i2), val in ioi_true_edges.items():\n",
    "    if val:\n",
    "        print(b1, b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292dfbf6",
   "metadata": {},
   "source": [
    "# Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "601a7d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                      Sentences from IOI vs ABC distribution                                       </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> IOI prompt                              </span>┃<span style=\"font-weight: bold\"> IOI subj </span>┃<span style=\"font-weight: bold\"> IOI indirect obj </span>┃<span style=\"font-weight: bold\"> ABC prompt                              </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ When <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Victoria</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jane</span> got a snack at   │ Jane     │ Victoria         │ When <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Victoria</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jane</span> got a snack at   │\n",
       "│ the store, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jane</span> decided to give it to   │          │                  │ the store, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jane</span> decided to give it to   │\n",
       "│ <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Victoria</span>                                │          │                  │ <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Victoria</span>                                │\n",
       "│                                         │          │                  │                                         │\n",
       "│ When <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Sullivan</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Rose</span> got a necklace   │ Sullivan │ Rose             │ When <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Sullivan</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Rose</span> got a necklace   │\n",
       "│ at the garden, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Sullivan</span> decided to give │          │                  │ at the garden, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Sullivan</span> decided to give │\n",
       "│ it to <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Rose</span>                              │          │                  │ it to <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Rose</span>                              │\n",
       "│                                         │          │                  │                                         │\n",
       "│ When <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Alan</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Alex</span> got a drink at the   │ Alex     │ Alan             │ When <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Alan</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Alex</span> got a drink at the   │\n",
       "│ store, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Alex</span> decided to give it to <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Alan</span>  │          │                  │ store, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Alex</span> decided to give it to <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Alan</span>  │\n",
       "│                                         │          │                  │                                         │\n",
       "│ Then, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jessica</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Crystal</span> had a long    │ Jessica  │ Crystal          │ Then, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jessica</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Crystal</span> had a long    │\n",
       "│ argument, and afterwards <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jessica</span> said   │          │                  │ argument, and afterwards <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jessica</span> said   │\n",
       "│ to <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Crystal</span>                              │          │                  │ to <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Crystal</span>                              │\n",
       "│                                         │          │                  │                                         │\n",
       "│ Then, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jonathan</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Kevin</span> were working   │ Kevin    │ Jonathan         │ Then, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jonathan</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Kevin</span> were working   │\n",
       "│ at the school. <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Kevin</span> decided to give a  │          │                  │ at the school. <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Kevin</span> decided to give a  │\n",
       "│ necklace to <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jonathan</span>                    │          │                  │ necklace to <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jonathan</span>                    │\n",
       "│                                         │          │                  │                                         │\n",
       "└─────────────────────────────────────────┴──────────┴──────────────────┴─────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                      Sentences from IOI vs ABC distribution                                       \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mIOI prompt                             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mIOI subj\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mIOI indirect obj\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mABC prompt                             \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ When \u001b[1;4;38;5;208mVictoria\u001b[0m and \u001b[1;4;38;5;208mJane\u001b[0m got a snack at   │ Jane     │ Victoria         │ When \u001b[1;4;38;5;208mVictoria\u001b[0m and \u001b[1;4;38;5;208mJane\u001b[0m got a snack at   │\n",
       "│ the store, \u001b[1;4;38;5;208mJane\u001b[0m decided to give it to   │          │                  │ the store, \u001b[1;4;38;5;208mJane\u001b[0m decided to give it to   │\n",
       "│ \u001b[1;4;38;5;208mVictoria\u001b[0m                                │          │                  │ \u001b[1;4;38;5;208mVictoria\u001b[0m                                │\n",
       "│                                         │          │                  │                                         │\n",
       "│ When \u001b[1;4;38;5;208mSullivan\u001b[0m and \u001b[1;4;38;5;208mRose\u001b[0m got a necklace   │ Sullivan │ Rose             │ When \u001b[1;4;38;5;208mSullivan\u001b[0m and \u001b[1;4;38;5;208mRose\u001b[0m got a necklace   │\n",
       "│ at the garden, \u001b[1;4;38;5;208mSullivan\u001b[0m decided to give │          │                  │ at the garden, \u001b[1;4;38;5;208mSullivan\u001b[0m decided to give │\n",
       "│ it to \u001b[1;4;38;5;208mRose\u001b[0m                              │          │                  │ it to \u001b[1;4;38;5;208mRose\u001b[0m                              │\n",
       "│                                         │          │                  │                                         │\n",
       "│ When \u001b[1;4;38;5;208mAlan\u001b[0m and \u001b[1;4;38;5;208mAlex\u001b[0m got a drink at the   │ Alex     │ Alan             │ When \u001b[1;4;38;5;208mAlan\u001b[0m and \u001b[1;4;38;5;208mAlex\u001b[0m got a drink at the   │\n",
       "│ store, \u001b[1;4;38;5;208mAlex\u001b[0m decided to give it to \u001b[1;4;38;5;208mAlan\u001b[0m  │          │                  │ store, \u001b[1;4;38;5;208mAlex\u001b[0m decided to give it to \u001b[1;4;38;5;208mAlan\u001b[0m  │\n",
       "│                                         │          │                  │                                         │\n",
       "│ Then, \u001b[1;4;38;5;208mJessica\u001b[0m and \u001b[1;4;38;5;208mCrystal\u001b[0m had a long    │ Jessica  │ Crystal          │ Then, \u001b[1;4;38;5;208mJessica\u001b[0m and \u001b[1;4;38;5;208mCrystal\u001b[0m had a long    │\n",
       "│ argument, and afterwards \u001b[1;4;38;5;208mJessica\u001b[0m said   │          │                  │ argument, and afterwards \u001b[1;4;38;5;208mJessica\u001b[0m said   │\n",
       "│ to \u001b[1;4;38;5;208mCrystal\u001b[0m                              │          │                  │ to \u001b[1;4;38;5;208mCrystal\u001b[0m                              │\n",
       "│                                         │          │                  │                                         │\n",
       "│ Then, \u001b[1;4;38;5;208mJonathan\u001b[0m and \u001b[1;4;38;5;208mKevin\u001b[0m were working   │ Kevin    │ Jonathan         │ Then, \u001b[1;4;38;5;208mJonathan\u001b[0m and \u001b[1;4;38;5;208mKevin\u001b[0m were working   │\n",
       "│ at the school. \u001b[1;4;38;5;208mKevin\u001b[0m decided to give a  │          │                  │ at the school. \u001b[1;4;38;5;208mKevin\u001b[0m decided to give a  │\n",
       "│ necklace to \u001b[1;4;38;5;208mJonathan\u001b[0m                    │          │                  │ necklace to \u001b[1;4;38;5;208mJonathan\u001b[0m                    │\n",
       "│                                         │          │                  │                                         │\n",
       "└─────────────────────────────────────────┴──────────┴──────────────────┴─────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ioi_task.ioi_dataset import IOIDataset, format_prompt, make_table\n",
    "N = 25\n",
    "clean_dataset = IOIDataset(\n",
    "    prompt_type='mixed',\n",
    "    N=N,\n",
    "    tokenizer=model.tokenizer,\n",
    "    prepend_bos=False,\n",
    "    seed=1,\n",
    "    device=device\n",
    ")\n",
    "corr_dataset = clean_dataset.gen_flipped_prompts('ABC->XYZ, BAB->XYZ')\n",
    "\n",
    "make_table(\n",
    "  colnames = [\"IOI prompt\", \"IOI subj\", \"IOI indirect obj\", \"ABC prompt\"],\n",
    "  cols = [\n",
    "    map(format_prompt, clean_dataset.sentences),\n",
    "    model.to_string(clean_dataset.s_tokenIDs).split(),\n",
    "    model.to_string(clean_dataset.io_tokenIDs).split(),\n",
    "    map(format_prompt, clean_dataset.sentences),\n",
    "  ],\n",
    "  title = \"Sentences from IOI vs ABC distribution\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6657f126",
   "metadata": {},
   "source": [
    "# Metric Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1b9d4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean direction: 2.805161237716675, Corrupt direction: 1.6208322048187256\n",
      "Clean metric: 1.0, Corrupt metric: 0.0\n"
     ]
    }
   ],
   "source": [
    "def ave_logit_diff(\n",
    "    logits: Float[Tensor, 'batch seq d_vocab'],\n",
    "    ioi_dataset: IOIDataset,\n",
    "    per_prompt: bool = False\n",
    "):\n",
    "    '''\n",
    "        Return average logit difference between correct and incorrect answers\n",
    "    '''\n",
    "    # Get logits for indirect objects\n",
    "    io_logits = logits[range(logits.size(0)), ioi_dataset.word_idx['end'], ioi_dataset.io_tokenIDs]\n",
    "    s_logits = logits[range(logits.size(0)), ioi_dataset.word_idx['end'], ioi_dataset.s_tokenIDs]\n",
    "    # Get logits for subject\n",
    "    logit_diff = io_logits - s_logits\n",
    "    return logit_diff if per_prompt else logit_diff.mean()\n",
    "\n",
    "with t.no_grad():\n",
    "    clean_logits = model(clean_dataset.toks)\n",
    "    corrupt_logits = model(corr_dataset.toks)\n",
    "    clean_logit_diff = ave_logit_diff(clean_logits, clean_dataset).item()\n",
    "    corrupt_logit_diff = ave_logit_diff(corrupt_logits, corr_dataset).item()\n",
    "\n",
    "def ioi_metric(\n",
    "    logits: Float[Tensor, \"batch seq_len d_vocab\"],\n",
    "    corrupted_logit_diff: float = corrupt_logit_diff,\n",
    "    clean_logit_diff: float = clean_logit_diff,\n",
    "    ioi_dataset: IOIDataset = clean_dataset\n",
    " ):\n",
    "    patched_logit_diff = ave_logit_diff(logits, ioi_dataset)\n",
    "    return (patched_logit_diff - corrupted_logit_diff) / (clean_logit_diff - corrupted_logit_diff)\n",
    "\n",
    "def abs_ioi_metric(logits: Float[Tensor, \"batch seq_len d_vocab\"]):\n",
    "    return abs(ioi_metric(logits))\n",
    "\n",
    "def negative_ioi_metric(logits: Float[Tensor, \"batch seq_len d_vocab\"]):\n",
    "    return -ioi_metric(logits)\n",
    "\n",
    "def negative_abs_ioi_metric(logits: Float[Tensor, \"batch seq_len d_vocab\"]):\n",
    "    return -abs_ioi_metric(logits)\n",
    "\n",
    "# Get clean and corrupt logit differences\n",
    "with t.no_grad():\n",
    "    clean_metric = ioi_metric(clean_logits, corrupt_logit_diff, clean_logit_diff, clean_dataset)\n",
    "    corrupt_metric = ioi_metric(corrupt_logits, corrupt_logit_diff, clean_logit_diff, corr_dataset)\n",
    "\n",
    "print(f'Clean direction: {clean_logit_diff}, Corrupt direction: {corrupt_logit_diff}')\n",
    "print(f'Clean metric: {clean_metric}, Corrupt metric: {corrupt_metric}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4858b398",
   "metadata": {},
   "source": [
    "# Run ACDC++/ACDC combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96d4e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_NAME = \"greaterthan_absval_edge\"\n",
    "acdcpp_convergence_thresh = 0.0035\n",
    "acdc_paper_thresh = 0.0575\n",
    "num_thresholds = 5\n",
    "\n",
    "ACDCPP_THRESHOLDS = np.linspace(\n",
    "    0.75 * acdcpp_convergence_thresh,\n",
    "    1.25 * acdcpp_convergence_thresh,\n",
    "    num_thresholds\n",
    ")\n",
    "ACDC_THRESHOLDS = np.linspace(\n",
    "    0.75 * acdc_paper_thresh,\n",
    "    1.25 * acdc_paper_thresh,\n",
    "    num_thresholds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58b4e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_exp = ACDCPPExperiment(\n",
    "    model,\n",
    "    clean_dataset,\n",
    "    corr_dataset,\n",
    "    acdc_metric=negative_abs_ioi_metric,\n",
    "    acdcpp_metric=negative_abs_ioi_metric,\n",
    "    acdc_thresholds=ACDC_THRESHOLDS,\n",
    "    acdcpp_thresholds=ACDCPP_THRESHOLDS,\n",
    "    run_name=RUN_NAME,\n",
    "    verbose=False,\n",
    "    attr_absolute_val=True,\n",
    "    save_graphs_after=0,\n",
    "    pruning_mode='edge',\n",
    "    no_pruned_nodes_attr=1,\n",
    ")\n",
    "pruned_heads, num_passes, pruned_attrs = combined_exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f099273f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
