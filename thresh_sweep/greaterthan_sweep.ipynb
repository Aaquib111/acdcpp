{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/canrager/.pyenv/versions/acdc_env/envs/acdcpp_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../Automatic-Circuit-Discovery/')\n",
    "sys.path.append('..')\n",
    "\n",
    "from acdc.greaterthan.utils import get_all_greaterthan_things\n",
    "from ACDCPPExperiment import ACDCPPExperiment\n",
    "from utils.prune_utils import get_3_caches, split_layers_and_heads\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "import numpy as np\n",
    "import torch as t\n",
    "import tqdm.notebook as tqdm\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = t.device('cuda') if t.cuda.is_available() else t.device('cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greaterthan\n",
    "## Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\n",
    "    'gpt2-small',\n",
    "    center_writing_weights=False,\n",
    "    center_unembed=False,\n",
    "    fold_ln=False,\n",
    "    device=device,\n",
    ")\n",
    "model.set_use_hook_mlp_in(True)\n",
    "model.set_use_split_qkv_input(True)\n",
    "model.set_use_attn_result(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n",
      "Moving model to device:  cpu\n",
      "\n",
      "Clean dataset samples\n",
      "The demonstrations lasted from the year 1267 to 12\n",
      "The assaults lasted from the year 1644 to 16\n",
      "The affair lasted from the year 1268 to 12\n",
      "The stature lasted from the year 1653 to 16\n",
      "The effort lasted from the year 1318 to 13\n",
      "\n",
      "Reference dataset samples\n",
      "The demonstrations lasted from the year 1201 to 12\n",
      "The assaults lasted from the year 1601 to 16\n",
      "The affair lasted from the year 1201 to 12\n",
      "The stature lasted from the year 1601 to 16\n",
      "The effort lasted from the year 1301 to 13\n"
     ]
    }
   ],
   "source": [
    "# Make clean dataset and reference dataset\n",
    "N = 25\n",
    "\n",
    "things = get_all_greaterthan_things(\n",
    "    num_examples=N, metric_name=\"greaterthan\", device=device\n",
    ")\n",
    "greaterthan_metric = things.validation_metric\n",
    "clean_ds = things.validation_data # clean data x_i\n",
    "corr_ds = things.validation_patch_data # corrupted data x_i'\n",
    "\n",
    "print(\"\\nClean dataset samples\")\n",
    "for i in range(5):\n",
    "    print(model.tokenizer.decode(clean_ds[i]))\n",
    "\n",
    "print(\"\\nReference dataset samples\")\n",
    "for i in range(5):\n",
    "    print(model.tokenizer.decode(corr_ds[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run combined ACDC++/ACDC experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_NAME = \"greaterthan_absval_edge\"\n",
    "acdcpp_greaterthan_convergence_thresh = 0.0004\n",
    "acdc_paper_thresh = 0.015\n",
    "num_thresholds = 5\n",
    "\n",
    "ACDCPP_THRESHOLDS = np.linspace(\n",
    "    0.75 * acdcpp_greaterthan_convergence_thresh,\n",
    "    1.25 * acdcpp_greaterthan_convergence_thresh,\n",
    "    num_thresholds\n",
    ")\n",
    "ACDC_THRESHOLDS = np.linspace(\n",
    "    0.75 * acdc_paper_thresh,\n",
    "    1.25 * acdc_paper_thresh,\n",
    "    num_thresholds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_exp = ACDCPPExperiment(\n",
    "    model,\n",
    "    clean_ds,\n",
    "    corr_ds,\n",
    "    acdc_metric=greaterthan_metric,\n",
    "    acdcpp_metric=greaterthan_metric,\n",
    "    acdc_thresholds=ACDC_THRESHOLDS,\n",
    "    acdcpp_thresholds=ACDCPP_THRESHOLDS,\n",
    "    run_name=RUN_NAME,\n",
    "    verbose=False,\n",
    "    attr_absolute_val=True,\n",
    "    save_graphs_after=0,\n",
    "    pruning_mode='edge',\n",
    "    no_pruned_nodes_attr=1,\n",
    ")\n",
    "pruned_heads, num_passes, pruned_attrs = combined_exp.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acdcpp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
