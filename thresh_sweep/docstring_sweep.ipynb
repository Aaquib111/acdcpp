{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2861525f-e65f-4dc8-9774-84a5a292a2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tn/nyh0947d6sngjfvtp7hbb0jr0000gn/T/ipykernel_40088/1557166804.py:8: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic('load_ext autoreload')\n",
      "/var/folders/tn/nyh0947d6sngjfvtp7hbb0jr0000gn/T/ipykernel_40088/1557166804.py:9: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic('autoreload 2')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/Automatic-Circuit-Discovery/')\n",
    "sys.path.append('..')\n",
    "import IPython\n",
    "ipython = get_ipython()\n",
    "if ipython is not None:\n",
    "    ipython.magic('load_ext autoreload')\n",
    "    ipython.magic('autoreload 2')\n",
    "import torch as t\n",
    "from torch import Tensor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "from acdc.TLACDCExperiment import TLACDCExperiment\n",
    "from acdc.docstring.utils import get_all_docstring_things\n",
    "from utils.prune_utils import get_3_caches, split_layers_and_heads\n",
    "from ACDCPPExperiment import ACDCPPExperiment\n",
    "device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5306b51d-26b3-47b8-9c08-f77b6a9350ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model attn-only-4l into HookedTransformer\n",
      "Moving model to device:  cpu\n"
     ]
    }
   ],
   "source": [
    "all_docstring_items = get_all_docstring_things(num_examples=40, seq_len=5, device=device, metric_name='docstring_metric', correct_incorrect_wandb=False)\n",
    "\n",
    "tl_model = all_docstring_items.tl_model\n",
    "validation_metric = all_docstring_items.validation_metric\n",
    "validation_data = all_docstring_items.validation_data\n",
    "validation_labels = all_docstring_items.validation_labels\n",
    "validation_patch_data = all_docstring_items.validation_patch_data\n",
    "test_metrics = all_docstring_items.test_metrics\n",
    "test_data = all_docstring_items.test_data\n",
    "test_labels = all_docstring_items.test_labels\n",
    "test_patch_data = all_docstring_items.test_patch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15465560-54a2-4433-8c8a-e13a152849e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_docstring_metric(logits):\n",
    "    return -abs(test_metrics['docstring_metric'](logits))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd81216c",
   "metadata": {},
   "source": [
    "# ACDC++ run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "714a757d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACDCPP_THRESHOLDS=array([0.75])\n",
      "ACDC_THRESHOLDS=array([0.75])\n"
     ]
    }
   ],
   "source": [
    "RUN_NAME = \"docstring_absval_edge\"\n",
    "acdcpp_docstring_convergence_thresh = 1#0.03\n",
    "acdc_paper_thresh = 1#0.067\n",
    "num_thresholds = 1#5\n",
    "\n",
    "ACDCPP_THRESHOLDS = np.linspace(\n",
    "    0.75 * acdcpp_docstring_convergence_thresh,\n",
    "    1.25 * acdcpp_docstring_convergence_thresh,\n",
    "    num_thresholds\n",
    ")\n",
    "ACDC_THRESHOLDS = np.linspace(\n",
    "    0.75 * acdc_paper_thresh,\n",
    "    1.25 * acdc_paper_thresh,\n",
    "    num_thresholds\n",
    ")\n",
    "\n",
    "print(f\"{ACDCPP_THRESHOLDS=}\")\n",
    "print(f\"{ACDC_THRESHOLDS=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8fbc8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:cache_all is deprecated and will eventually be removed, use add_caching_hooks or run_with_cache\n",
      "WARNING:root:cache_all is deprecated and will eventually be removed, use add_caching_hooks or run_with_cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.current_node=TLACDCInterpNode(blocks.3.hook_resid_post, [:])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Edge pruning: 100%|██████████| 193/193 [00:00<00:00, 263.10it/s]\n",
      "ACDC++:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acdcpp_threshold=0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:cache_all is deprecated and will eventually be removed, use add_caching_hooks or run_with_cache\n",
      "WARNING:root:cache_all is deprecated and will eventually be removed, use add_caching_hooks or run_with_cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acdc_threshold=0.75\n",
      "self.current_node=TLACDCInterpNode(blocks.3.hook_resid_post, [:])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ACDC:   0%|          | 0/1 [05:29<?, ?it/s]\n",
      "ACDC++:   0%|          | 0/1 [05:29<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/canrager/acdcpp/thresh_sweep/docstring_sweep.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/canrager/acdcpp/thresh_sweep/docstring_sweep.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m combined_exp \u001b[39m=\u001b[39m ACDCPPExperiment(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/canrager/acdcpp/thresh_sweep/docstring_sweep.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     tl_model,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/canrager/acdcpp/thresh_sweep/docstring_sweep.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     test_data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/canrager/acdcpp/thresh_sweep/docstring_sweep.ipynb#W5sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     no_pruned_nodes_attr\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/canrager/acdcpp/thresh_sweep/docstring_sweep.ipynb#W5sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/canrager/acdcpp/thresh_sweep/docstring_sweep.ipynb#W5sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m present_edge_attrs, num_passes, acdcpp_attrs \u001b[39m=\u001b[39m combined_exp\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[0;32m~/acdcpp/thresh_sweep/../ACDCPPExperiment.py:208\u001b[0m, in \u001b[0;36mACDCPPExperiment.run\u001b[0;34m(self, save_after_acdcpp, save_after_acdc)\u001b[0m\n\u001b[1;32m    200\u001b[0m prepruned_exp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_acdcpp(exp, acdcpp_attrs, acdcpp_threshold)\n\u001b[1;32m    201\u001b[0m \u001b[39m# Do not save acdcpp-graphs for now.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[39m# Only applying threshold to this one as these graphs tend to be HUGE\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[39m# if acdcpp_threshold >= self.save_graphs_after:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    206\u001b[0m \n\u001b[1;32m    207\u001b[0m \u001b[39m# Run ACDC on pruned subgraph\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m acdc_edge_attr, passes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_acdc(prepruned_exp)\n\u001b[1;32m    209\u001b[0m \u001b[39m# print('Saving ACDC Graph')\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[39m# show(prepruned_exp.corr, fname=f'ims/{self.run_name}/thresh{acdc_threshold}_after_acdc.png')\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     \n\u001b[1;32m    212\u001b[0m \u001b[39m# Save results\u001b[39;00m\n\u001b[1;32m    213\u001b[0m present_edge_attrs[acdcpp_threshold][acdc_threshold] \u001b[39m=\u001b[39m acdc_edge_attr\n",
      "File \u001b[0;32m~/acdcpp/thresh_sweep/../ACDCPPExperiment.py:150\u001b[0m, in \u001b[0;36mACDCPPExperiment.run_acdc\u001b[0;34m(self, exp)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mRunning ACDC\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    149\u001b[0m \u001b[39mwhile\u001b[39;00m exp\u001b[39m.\u001b[39mcurrent_node:\n\u001b[0;32m--> 150\u001b[0m     exp\u001b[39m.\u001b[39;49mstep(testing\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    152\u001b[0m \u001b[39mreturn\u001b[39;00m (get_present_edges(exp\u001b[39m.\u001b[39mcorr), exp\u001b[39m.\u001b[39mnum_passes)\n",
      "File \u001b[0;32m~/acdcpp/Automatic-Circuit-Discovery/acdc/TLACDCExperiment.py:671\u001b[0m, in \u001b[0;36mTLACDCExperiment.step\u001b[0;34m(self, early_stop, testing)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[39m# increment the current node\u001b[39;00m\n\u001b[1;32m    670\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mincrement_current_node()\n\u001b[0;32m--> 671\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate_cur_metric(recalc_metric\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, recalc_edges\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/acdcpp/Automatic-Circuit-Discovery/acdc/TLACDCExperiment.py:201\u001b[0m, in \u001b[0;36mTLACDCExperiment.update_cur_metric\u001b[0;34m(self, recalc_metric, recalc_edges, initial)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_cur_metric\u001b[39m(\u001b[39mself\u001b[39m, recalc_metric\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, recalc_edges\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, initial\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    200\u001b[0m     \u001b[39mif\u001b[39;00m recalc_metric:\n\u001b[0;32m--> 201\u001b[0m         logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mds)\n\u001b[1;32m    202\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcur_metric \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetric(logits)\n\u001b[1;32m    203\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msecond_metric \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/acdc_env/envs/acdcpp_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/acdc_env/envs/acdcpp_env/lib/python3.10/site-packages/transformer_lens/HookedTransformer.py:405\u001b[0m, in \u001b[0;36mHookedTransformer.forward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, stop_at_layer, past_kv_cache, past_left_attention_mask)\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[39mif\u001b[39;00m shortformer_pos_embed \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    401\u001b[0m         shortformer_pos_embed \u001b[39m=\u001b[39m shortformer_pos_embed\u001b[39m.\u001b[39mto(\n\u001b[1;32m    402\u001b[0m             devices\u001b[39m.\u001b[39mget_device_for_block_index(i, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg)\n\u001b[1;32m    403\u001b[0m         )\n\u001b[0;32m--> 405\u001b[0m     residual \u001b[39m=\u001b[39m block(\n\u001b[1;32m    406\u001b[0m         residual,\n\u001b[1;32m    407\u001b[0m         past_kv_cache_entry\u001b[39m=\u001b[39;49mpast_kv_cache[i]\n\u001b[1;32m    408\u001b[0m         \u001b[39mif\u001b[39;49;00m past_kv_cache \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m    409\u001b[0m         \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,  \u001b[39m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each block\u001b[39;49;00m\n\u001b[1;32m    410\u001b[0m         shortformer_pos_embed\u001b[39m=\u001b[39;49mshortformer_pos_embed,\n\u001b[1;32m    411\u001b[0m         left_attention_mask\u001b[39m=\u001b[39;49mleft_attention_mask,\n\u001b[1;32m    412\u001b[0m     )  \u001b[39m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[39mif\u001b[39;00m stop_at_layer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    415\u001b[0m     \u001b[39m# When we stop at an early layer, we end here rather than doing further computation\u001b[39;00m\n\u001b[1;32m    416\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/acdc_env/envs/acdcpp_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/acdc_env/envs/acdcpp_env/lib/python3.10/site-packages/transformer_lens/components.py:1043\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, left_attention_mask)\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[39mif\u001b[39;00m shortformer_pos_embed \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1037\u001b[0m         shortformer_pos_embed \u001b[39m=\u001b[39m add_head_dimension(shortformer_pos_embed)\n\u001b[1;32m   1039\u001b[0m attn_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhook_attn_out(\n\u001b[1;32m   1040\u001b[0m     \u001b[39m# hook the residual stream states that are used to calculate the\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m     \u001b[39m# queries, keys and values, independently.\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[39m# Then take the layer norm of these inputs, and pass these to the attention module.\u001b[39;00m\n\u001b[0;32m-> 1043\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattn(\n\u001b[1;32m   1044\u001b[0m         query_input\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mln1(query_input)\n\u001b[1;32m   1045\u001b[0m         \u001b[39m+\u001b[39;49m (\u001b[39m0.0\u001b[39;49m \u001b[39mif\u001b[39;49;00m shortformer_pos_embed \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m shortformer_pos_embed),\n\u001b[1;32m   1046\u001b[0m         key_input\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mln1(key_input)\n\u001b[1;32m   1047\u001b[0m         \u001b[39m+\u001b[39;49m (\u001b[39m0.0\u001b[39;49m \u001b[39mif\u001b[39;49;00m shortformer_pos_embed \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m shortformer_pos_embed),\n\u001b[1;32m   1048\u001b[0m         value_input\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mln1(value_input),\n\u001b[1;32m   1049\u001b[0m         past_kv_cache_entry\u001b[39m=\u001b[39;49mpast_kv_cache_entry,\n\u001b[1;32m   1050\u001b[0m         left_attention_mask\u001b[39m=\u001b[39;49mleft_attention_mask,\n\u001b[1;32m   1051\u001b[0m     )\n\u001b[1;32m   1052\u001b[0m )  \u001b[39m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg\u001b[39m.\u001b[39mattn_only \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg\u001b[39m.\u001b[39mparallel_attn_mlp:\n\u001b[1;32m   1054\u001b[0m     resid_mid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhook_resid_mid(\n\u001b[1;32m   1055\u001b[0m         resid_pre \u001b[39m+\u001b[39m attn_out\n\u001b[1;32m   1056\u001b[0m     )  \u001b[39m# [batch, pos, d_model]\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/acdc_env/envs/acdcpp_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/acdc_env/envs/acdcpp_env/lib/python3.10/site-packages/transformer_lens/components.py:641\u001b[0m, in \u001b[0;36mAttention.forward\u001b[0;34m(self, query_input, key_input, value_input, past_kv_cache_entry, additive_attention_mask, left_attention_mask)\u001b[0m\n\u001b[1;32m    626\u001b[0m     out \u001b[39m=\u001b[39m (\n\u001b[1;32m    627\u001b[0m         (\n\u001b[1;32m    628\u001b[0m             einsum(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb_O\n\u001b[1;32m    637\u001b[0m     )  \u001b[39m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    639\u001b[0m     \u001b[39m# Explicitly calculate the attention result so it can be accessed by a hook\u001b[39;00m\n\u001b[1;32m    640\u001b[0m     \u001b[39m# This is off by default because it can easily eat through your GPU memory.\u001b[39;00m\n\u001b[0;32m--> 641\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhook_result(\n\u001b[1;32m    642\u001b[0m         einsum(\n\u001b[1;32m    643\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mbatch pos head_index d_head, \u001b[39;49m\u001b[39m\\\u001b[39;49;00m\n\u001b[1;32m    644\u001b[0m \u001b[39m                head_index d_head d_model -> \u001b[39;49m\u001b[39m\\\u001b[39;49;00m\n\u001b[1;32m    645\u001b[0m \u001b[39m                batch pos head_index d_model\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    646\u001b[0m             z,\n\u001b[1;32m    647\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mW_O,\n\u001b[1;32m    648\u001b[0m         )\n\u001b[1;32m    649\u001b[0m     )  \u001b[39m# [batch, pos, head_index, d_model]\u001b[39;00m\n\u001b[1;32m    650\u001b[0m     out \u001b[39m=\u001b[39m (\n\u001b[1;32m    651\u001b[0m         einops\u001b[39m.\u001b[39mreduce(\n\u001b[1;32m    652\u001b[0m             result, \u001b[39m\"\u001b[39m\u001b[39mbatch position index model->batch position model\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msum\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    653\u001b[0m         )\n\u001b[1;32m    654\u001b[0m         \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb_O\n\u001b[1;32m    655\u001b[0m     )  \u001b[39m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    656\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.pyenv/versions/acdc_env/envs/acdcpp_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1215\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1214\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m (\u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mvalues(), \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m-> 1215\u001b[0m         hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39;49m, \u001b[39minput\u001b[39;49m, result)\n\u001b[1;32m   1216\u001b[0m         \u001b[39mif\u001b[39;00m hook_result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1217\u001b[0m             result \u001b[39m=\u001b[39m hook_result\n",
      "File \u001b[0;32m~/.pyenv/versions/acdc_env/envs/acdcpp_env/lib/python3.10/site-packages/transformer_lens/hook_points.py:67\u001b[0m, in \u001b[0;36mHookPoint.add_hook.<locals>.full_hook\u001b[0;34m(module, module_input, module_output)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfull_hook\u001b[39m(module, module_input, module_output):\n\u001b[0;32m---> 67\u001b[0m     \u001b[39mreturn\u001b[39;00m hook(module_output, hook\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/acdcpp/Automatic-Circuit-Discovery/acdc/TLACDCExperiment.py:255\u001b[0m, in \u001b[0;36mTLACDCExperiment.sender_hook\u001b[0;34m(self, z, hook, verbose, cache, device)\u001b[0m\n\u001b[1;32m    253\u001b[0m     tens \u001b[39m=\u001b[39m z\u001b[39m.\u001b[39mcpu()\n\u001b[1;32m    254\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 255\u001b[0m     tens \u001b[39m=\u001b[39m z\u001b[39m.\u001b[39;49mclone()\n\u001b[1;32m    256\u001b[0m     \u001b[39mif\u001b[39;00m device \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m         tens \u001b[39m=\u001b[39m tens\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "combined_exp = ACDCPPExperiment(\n",
    "    tl_model,\n",
    "    test_data,\n",
    "    test_patch_data,\n",
    "    acdc_metric=test_metrics['docstring_metric'],\n",
    "    acdcpp_metric=abs_docstring_metric,\n",
    "    acdc_thresholds=ACDC_THRESHOLDS,\n",
    "    acdcpp_thresholds=ACDCPP_THRESHOLDS,\n",
    "    run_name=RUN_NAME,\n",
    "    verbose=False,\n",
    "    attr_absolute_val=True,\n",
    "    save_graphs_after=0,\n",
    "    pruning_mode='edge',\n",
    "    no_pruned_nodes_attr=1,\n",
    ")\n",
    "present_edge_attrs, num_passes, acdcpp_attrs = combined_exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2083a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
