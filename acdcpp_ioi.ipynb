{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6606875e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('Automatic-Circuit-Discovery/')\n",
    "import re\n",
    "\n",
    "import acdc\n",
    "from acdc.TLACDCExperiment import TLACDCExperiment\n",
    "from acdc.acdc_utils import TorchIndex, EdgeType\n",
    "import numpy as np\n",
    "import torch as t\n",
    "from torch import Tensor\n",
    "import einops\n",
    "import itertools\n",
    "\n",
    "from transformer_lens import HookedTransformer, ActivationCache\n",
    "\n",
    "import tqdm.notebook as tqdm\n",
    "import plotly\n",
    "from rich import print as rprint\n",
    "from rich.table import Table\n",
    "\n",
    "from jaxtyping import Float, Bool\n",
    "from typing import Callable, Tuple, Union, Dict, Optional\n",
    "\n",
    "device = t.device('cuda') if t.cuda.is_available() else t.device('cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a16eab",
   "metadata": {},
   "source": [
    "# Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20df2bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\n",
    "    'gpt2-small',\n",
    "    center_writing_weights=False,\n",
    "    center_unembed=False,\n",
    "    fold_ln=False,\n",
    "    device=device,\n",
    ")\n",
    "model.set_use_hook_mlp_in(True)\n",
    "model.set_use_split_qkv_input(True)\n",
    "model.set_use_attn_result(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292dfbf6",
   "metadata": {},
   "source": [
    "# Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "601a7d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                      Sentences from IOI vs ABC distribution                                       </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> IOI prompt                              </span>┃<span style=\"font-weight: bold\"> IOI subj </span>┃<span style=\"font-weight: bold\"> IOI indirect obj </span>┃<span style=\"font-weight: bold\"> ABC prompt                              </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ When <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Victoria</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jane</span> got a snack at   │ Jane     │ Victoria         │ When <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Victoria</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jane</span> got a snack at   │\n",
       "│ the store, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jane</span> decided to give it to   │          │                  │ the store, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jane</span> decided to give it to   │\n",
       "│ <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Victoria</span>                                │          │                  │ <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Victoria</span>                                │\n",
       "│                                         │          │                  │                                         │\n",
       "│ When <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Sullivan</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Rose</span> got a necklace   │ Sullivan │ Rose             │ When <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Sullivan</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Rose</span> got a necklace   │\n",
       "│ at the garden, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Sullivan</span> decided to give │          │                  │ at the garden, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Sullivan</span> decided to give │\n",
       "│ it to <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Rose</span>                              │          │                  │ it to <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Rose</span>                              │\n",
       "│                                         │          │                  │                                         │\n",
       "│ When <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Alan</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Alex</span> got a drink at the   │ Alex     │ Alan             │ When <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Alan</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Alex</span> got a drink at the   │\n",
       "│ store, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Alex</span> decided to give it to <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Alan</span>  │          │                  │ store, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Alex</span> decided to give it to <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Alan</span>  │\n",
       "│                                         │          │                  │                                         │\n",
       "│ Then, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jessica</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Crystal</span> had a long    │ Jessica  │ Crystal          │ Then, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jessica</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Crystal</span> had a long    │\n",
       "│ argument, and afterwards <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jessica</span> said   │          │                  │ argument, and afterwards <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jessica</span> said   │\n",
       "│ to <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Crystal</span>                              │          │                  │ to <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Crystal</span>                              │\n",
       "│                                         │          │                  │                                         │\n",
       "│ Then, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jonathan</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Kevin</span> were working   │ Kevin    │ Jonathan         │ Then, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jonathan</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Kevin</span> were working   │\n",
       "│ at the school. <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Kevin</span> decided to give a  │          │                  │ at the school. <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Kevin</span> decided to give a  │\n",
       "│ necklace to <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jonathan</span>                    │          │                  │ necklace to <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jonathan</span>                    │\n",
       "│                                         │          │                  │                                         │\n",
       "└─────────────────────────────────────────┴──────────┴──────────────────┴─────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                      Sentences from IOI vs ABC distribution                                       \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mIOI prompt                             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mIOI subj\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mIOI indirect obj\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mABC prompt                             \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ When \u001b[1;4;38;5;208mVictoria\u001b[0m and \u001b[1;4;38;5;208mJane\u001b[0m got a snack at   │ Jane     │ Victoria         │ When \u001b[1;4;38;5;208mVictoria\u001b[0m and \u001b[1;4;38;5;208mJane\u001b[0m got a snack at   │\n",
       "│ the store, \u001b[1;4;38;5;208mJane\u001b[0m decided to give it to   │          │                  │ the store, \u001b[1;4;38;5;208mJane\u001b[0m decided to give it to   │\n",
       "│ \u001b[1;4;38;5;208mVictoria\u001b[0m                                │          │                  │ \u001b[1;4;38;5;208mVictoria\u001b[0m                                │\n",
       "│                                         │          │                  │                                         │\n",
       "│ When \u001b[1;4;38;5;208mSullivan\u001b[0m and \u001b[1;4;38;5;208mRose\u001b[0m got a necklace   │ Sullivan │ Rose             │ When \u001b[1;4;38;5;208mSullivan\u001b[0m and \u001b[1;4;38;5;208mRose\u001b[0m got a necklace   │\n",
       "│ at the garden, \u001b[1;4;38;5;208mSullivan\u001b[0m decided to give │          │                  │ at the garden, \u001b[1;4;38;5;208mSullivan\u001b[0m decided to give │\n",
       "│ it to \u001b[1;4;38;5;208mRose\u001b[0m                              │          │                  │ it to \u001b[1;4;38;5;208mRose\u001b[0m                              │\n",
       "│                                         │          │                  │                                         │\n",
       "│ When \u001b[1;4;38;5;208mAlan\u001b[0m and \u001b[1;4;38;5;208mAlex\u001b[0m got a drink at the   │ Alex     │ Alan             │ When \u001b[1;4;38;5;208mAlan\u001b[0m and \u001b[1;4;38;5;208mAlex\u001b[0m got a drink at the   │\n",
       "│ store, \u001b[1;4;38;5;208mAlex\u001b[0m decided to give it to \u001b[1;4;38;5;208mAlan\u001b[0m  │          │                  │ store, \u001b[1;4;38;5;208mAlex\u001b[0m decided to give it to \u001b[1;4;38;5;208mAlan\u001b[0m  │\n",
       "│                                         │          │                  │                                         │\n",
       "│ Then, \u001b[1;4;38;5;208mJessica\u001b[0m and \u001b[1;4;38;5;208mCrystal\u001b[0m had a long    │ Jessica  │ Crystal          │ Then, \u001b[1;4;38;5;208mJessica\u001b[0m and \u001b[1;4;38;5;208mCrystal\u001b[0m had a long    │\n",
       "│ argument, and afterwards \u001b[1;4;38;5;208mJessica\u001b[0m said   │          │                  │ argument, and afterwards \u001b[1;4;38;5;208mJessica\u001b[0m said   │\n",
       "│ to \u001b[1;4;38;5;208mCrystal\u001b[0m                              │          │                  │ to \u001b[1;4;38;5;208mCrystal\u001b[0m                              │\n",
       "│                                         │          │                  │                                         │\n",
       "│ Then, \u001b[1;4;38;5;208mJonathan\u001b[0m and \u001b[1;4;38;5;208mKevin\u001b[0m were working   │ Kevin    │ Jonathan         │ Then, \u001b[1;4;38;5;208mJonathan\u001b[0m and \u001b[1;4;38;5;208mKevin\u001b[0m were working   │\n",
       "│ at the school. \u001b[1;4;38;5;208mKevin\u001b[0m decided to give a  │          │                  │ at the school. \u001b[1;4;38;5;208mKevin\u001b[0m decided to give a  │\n",
       "│ necklace to \u001b[1;4;38;5;208mJonathan\u001b[0m                    │          │                  │ necklace to \u001b[1;4;38;5;208mJonathan\u001b[0m                    │\n",
       "│                                         │          │                  │                                         │\n",
       "└─────────────────────────────────────────┴──────────┴──────────────────┴─────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ioi_dataset import IOIDataset, format_prompt, make_table\n",
    "N = 25\n",
    "clean_dataset = IOIDataset(\n",
    "    prompt_type='mixed',\n",
    "    N=N,\n",
    "    tokenizer=model.tokenizer,\n",
    "    prepend_bos=False,\n",
    "    seed=1,\n",
    "    device=device\n",
    ")\n",
    "corr_dataset = clean_dataset.gen_flipped_prompts('ABC->XYZ, BAB->XYZ')\n",
    "\n",
    "make_table(\n",
    "  colnames = [\"IOI prompt\", \"IOI subj\", \"IOI indirect obj\", \"ABC prompt\"],\n",
    "  cols = [\n",
    "    map(format_prompt, clean_dataset.sentences),\n",
    "    model.to_string(clean_dataset.s_tokenIDs).split(),\n",
    "    model.to_string(clean_dataset.io_tokenIDs).split(),\n",
    "    map(format_prompt, clean_dataset.sentences),\n",
    "  ],\n",
    "  title = \"Sentences from IOI vs ABC distribution\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6657f126",
   "metadata": {},
   "source": [
    "# Metric Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1b9d4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean direction: 2.805161476135254, Corrupt direction: 1.6808288097381592\n",
      "Clean metric: 1.0, Corrupt metric: 0.0\n"
     ]
    }
   ],
   "source": [
    "def ave_logit_diff(\n",
    "    logits: Float[Tensor, 'batch seq d_vocab'],\n",
    "    ioi_dataset: IOIDataset,\n",
    "    per_prompt: bool = False\n",
    "):\n",
    "    '''\n",
    "        Return average logit difference between correct and incorrect answers\n",
    "    '''\n",
    "    # Get logits for indirect objects\n",
    "    io_logits = logits[range(logits.size(0)), ioi_dataset.word_idx['end'], ioi_dataset.io_tokenIDs]\n",
    "    s_logits = logits[range(logits.size(0)), ioi_dataset.word_idx['end'], ioi_dataset.s_tokenIDs]\n",
    "    # Get logits for subject\n",
    "    logit_diff = io_logits - s_logits\n",
    "    return logit_diff if per_prompt else logit_diff.mean()\n",
    "\n",
    "with t.no_grad():\n",
    "    clean_logits = model(clean_dataset.toks)\n",
    "    corrupt_logits = model(corr_dataset.toks)\n",
    "    clean_logit_diff = ave_logit_diff(clean_logits, clean_dataset).item()\n",
    "    corrupt_logit_diff = ave_logit_diff(corrupt_logits, corr_dataset).item()\n",
    "\n",
    "def ioi_metric(\n",
    "    logits: Float[Tensor, \"batch seq_len d_vocab\"],\n",
    "    corrupted_logit_diff: float = corrupt_logit_diff,\n",
    "    clean_logit_diff: float = clean_logit_diff,\n",
    "    ioi_dataset: IOIDataset = clean_dataset\n",
    " ):\n",
    "    patched_logit_diff = ave_logit_diff(logits, ioi_dataset)\n",
    "    return (patched_logit_diff - corrupted_logit_diff) / (clean_logit_diff - corrupted_logit_diff)\n",
    "\n",
    "def negative_ioi_metric(logits: Float[Tensor, \"batch seq_len d_vocab\"]):\n",
    "    return -ioi_metric(logits)\n",
    "    \n",
    "# Get clean and corrupt logit differences\n",
    "with t.no_grad():\n",
    "    clean_metric = ioi_metric(clean_logits, corrupt_logit_diff, clean_logit_diff, clean_dataset)\n",
    "    corrupt_metric = ioi_metric(corrupt_logits, corrupt_logit_diff, clean_logit_diff, corr_dataset)\n",
    "\n",
    "print(f'Clean direction: {clean_logit_diff}, Corrupt direction: {corrupt_logit_diff}')\n",
    "print(f'Clean metric: {clean_metric}, Corrupt metric: {corrupt_metric}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4293f9c7",
   "metadata": {},
   "source": [
    "# Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86d10f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_redundant_node(exp, node, safe=True, allow_fails=True):\n",
    "        if safe:\n",
    "            for parent_name in exp.corr.edges[node.name][node.index]:\n",
    "                for parent_index in exp.corr.edges[node.name][node.index][parent_name]:\n",
    "                    if exp.corr.edges[node.name][node.index][parent_name][parent_index].present:\n",
    "                        raise Exception(f\"You should not be removing a node that is still used by another node {node} {(parent_name, parent_index)}\")\n",
    "\n",
    "        bfs = [node]\n",
    "        bfs_idx = 0\n",
    "\n",
    "        while bfs_idx < len(bfs):\n",
    "            cur_node = bfs[bfs_idx]\n",
    "            bfs_idx += 1\n",
    "\n",
    "            children = exp.corr.graph[cur_node.name][cur_node.index].children\n",
    "\n",
    "            for child_node in children:\n",
    "                if not cur_node.index in exp.corr.edges[child_node.name][child_node.index][cur_node.name]:\n",
    "                    #print(f'\\t CANT remove edge {cur_node.name}, {cur_node.index} <-> {child_node.name}, {child_node.index}')\n",
    "                    continue\n",
    "                    \n",
    "                try:\n",
    "                    #print(f'\\t Removing edge {cur_node.name}, {cur_node.index} <-> {child_node.name}, {child_node.index}')\n",
    "                    exp.corr.remove_edge(\n",
    "                        child_node.name, child_node.index, cur_node.name, cur_node.index\n",
    "                    )\n",
    "                except KeyError as e:\n",
    "                    print(\"Got an error\", e)\n",
    "                    if allow_fails:\n",
    "                        continue\n",
    "                    else:\n",
    "                        raise e\n",
    "\n",
    "                remove_this = True\n",
    "                for parent_of_child_name in exp.corr.edges[child_node.name][child_node.index]:\n",
    "                    for parent_of_child_index in exp.corr.edges[child_node.name][child_node.index][parent_of_child_name]:\n",
    "                        if exp.corr.edges[child_node.name][child_node.index][parent_of_child_name][parent_of_child_index].present:\n",
    "                            remove_this = False\n",
    "                            break\n",
    "                    if not remove_this:\n",
    "                        break\n",
    "\n",
    "                if remove_this and child_node not in bfs:\n",
    "                    bfs.append(child_node)\n",
    "\n",
    "def remove_node(exp, node):\n",
    "    '''\n",
    "        Method that removes node from model. Assumes children point towards\n",
    "        the end of the residual stream and parents point towards the beginning.\n",
    "\n",
    "        exp: A TLACDCExperiment object with a reverse top sorted graph\n",
    "        node: A TLACDCInterpNode describing the node to remove\n",
    "        root: Initally the first node in the graph\n",
    "    '''\n",
    "    #Removing all edges pointing to the node\n",
    "    remove_edges = []\n",
    "    for p_name in exp.corr.edges[node.name][node.index]:\n",
    "        for p_idx in exp.corr.edges[node.name][node.index][p_name]:\n",
    "            edge = exp.corr.edges[node.name][node.index][p_name][p_idx]\n",
    "            remove_edges.append((node.name, node.index, p_name, p_idx))\n",
    "            edge.present = False\n",
    "    for n_name, n_idx, p_name, p_idx in remove_edges:\n",
    "        #print(f'\\t Removing edge {p_name}, {p_idx} <-> {n_name}, {n_idx}')\n",
    "        exp.corr.remove_edge(\n",
    "            n_name, n_idx, p_name, p_idx\n",
    "        )\n",
    "    # Removing all outgoing edges from the node using BFS\n",
    "    remove_redundant_node(exp, node, safe=False)\n",
    "\n",
    "def find_attn_node(exp, layer, head):\n",
    "    return exp.corr.graph[f'blocks.{layer}.attn.hook_result'][TorchIndex([None, None, head])]\n",
    "\n",
    "def find_attn_node_qkv(exp, layer, head):\n",
    "    nodes = []\n",
    "    for qkv in ['q', 'k', 'v']:\n",
    "        nodes.append(exp.corr.graph[f'blocks.{layer}.attn.hook_{qkv}'][TorchIndex([None, None, head])])\n",
    "        nodes.append(exp.corr.graph[f'blocks.{layer}.hook_{qkv}_input'][TorchIndex([None, None, head])])\n",
    "    return nodes\n",
    "    \n",
    "def split_layers_and_heads(act: Tensor, model: HookedTransformer) -> Tensor:\n",
    "    return einops.rearrange(act, '(layer head) batch seq d_model -> layer head batch seq d_model',\n",
    "                            layer=model.cfg.n_layers,\n",
    "                            head=model.cfg.n_heads)\n",
    "\n",
    "hook_filter = lambda name: name.endswith(\"ln1.hook_normalized\") or name.endswith(\"attn.hook_result\")\n",
    "def get_3_caches(model, clean_input, corrupted_input, metric):\n",
    "    # cache the activations and gradients of the clean inputs\n",
    "    model.reset_hooks()\n",
    "    clean_cache = {}\n",
    "\n",
    "    def forward_cache_hook(act, hook):\n",
    "        clean_cache[hook.name] = act.detach()\n",
    "\n",
    "    model.add_hook(hook_filter, forward_cache_hook, \"fwd\")\n",
    "\n",
    "    clean_grad_cache = {}\n",
    "\n",
    "    def backward_cache_hook(act, hook):\n",
    "        clean_grad_cache[hook.name] = act.detach()\n",
    "\n",
    "    model.add_hook(hook_filter, backward_cache_hook, \"bwd\")\n",
    "\n",
    "    value = metric(model(clean_input))\n",
    "    value.backward()\n",
    "\n",
    "    # cache the activations of the corrupted inputs\n",
    "    model.reset_hooks()\n",
    "    corrupted_cache = {}\n",
    "\n",
    "    def forward_cache_hook(act, hook):\n",
    "        corrupted_cache[hook.name] = act.detach()\n",
    "\n",
    "    model.add_hook(hook_filter, forward_cache_hook, \"fwd\")\n",
    "    model(corrupted_input)\n",
    "    model.reset_hooks()\n",
    "\n",
    "    clean_cache = ActivationCache(clean_cache, model)\n",
    "    corrupted_cache = ActivationCache(corrupted_cache, model)\n",
    "    clean_grad_cache = ActivationCache(clean_grad_cache, model)\n",
    "    return clean_cache, corrupted_cache, clean_grad_cache\n",
    "\n",
    "def acdc_nodes(model: HookedTransformer,\n",
    "              clean_input: Tensor,\n",
    "              corrupted_input: Tensor,\n",
    "              metric: Callable[[Tensor], Tensor],\n",
    "              threshold: float,\n",
    "              exp: TLACDCExperiment,\n",
    "              attr_absolute_val: bool = False) -> Tuple[\n",
    "                  HookedTransformer, Bool[Tensor, 'n_layer n_heads']]:\n",
    "    '''\n",
    "    Runs attribution-patching-based ACDC on the model, using the given metric and data.\n",
    "    Returns the pruned model, and which heads were pruned.\n",
    "\n",
    "    Arguments:\n",
    "        model: the model to prune\n",
    "        clean_input: the input to the model that contains should elicit the behavior we're looking for\n",
    "        corrupted_input: the input to the model that should elicit random behavior\n",
    "        metric: the metric to use to compare the model's performance on the clean and corrupted inputs\n",
    "        threshold: the threshold below which to prune\n",
    "        create_model: a function that returns a new model of the same type as the input model\n",
    "        attr_absolute_val: whether to take the absolute value of the attribution before thresholding\n",
    "    '''\n",
    "    # get the 2 fwd and 1 bwd caches; cache \"normalized\" and \"result\" of attn layers\n",
    "    clean_cache, corrupted_cache, clean_grad_cache = get_3_caches(model, clean_input, corrupted_input, metric)\n",
    "\n",
    "    # compute first-order Taylor approximation for each node to get the attribution\n",
    "    clean_head_act = clean_cache.stack_head_results()\n",
    "    corr_head_act = corrupted_cache.stack_head_results()\n",
    "    clean_grad_act = clean_grad_cache.stack_head_results()\n",
    "\n",
    "    # compute attributions of each node\n",
    "    node_attr = (clean_head_act - corr_head_act) * clean_grad_act\n",
    "    # separate layers and heads, sum over d_model (to complete the dot product), batch, and seq\n",
    "    node_attr = split_layers_and_heads(node_attr, model).sum((2, 3, 4))\n",
    "\n",
    "    if attr_absolute_val:\n",
    "        node_attr = node_attr.abs()\n",
    "    del clean_cache\n",
    "    del clean_head_act\n",
    "    del corrupted_cache\n",
    "    del corr_head_act\n",
    "    del clean_grad_cache\n",
    "    del clean_grad_act\n",
    "    t.cuda.empty_cache()\n",
    "    # prune all nodes whose attribution is below the threshold\n",
    "    should_prune = node_attr < threshold\n",
    "    pruned_nodes_attr = {}\n",
    "    for layer, head in itertools.product(range(model.cfg.n_layers), range(model.cfg.n_heads)):\n",
    "        if should_prune[layer, head]:\n",
    "            # REMOVING NODE\n",
    "            print(f'PRUNING L{layer}H{head} with attribution {node_attr[layer, head]}')\n",
    "            # Find the corresponding node in computation graph\n",
    "            node = find_attn_node(exp, layer, head)\n",
    "            print(f'\\tFound node {node.name}')\n",
    "            # Prune node\n",
    "            remove_node(exp, node)\n",
    "            print(f'\\tRemoved node {node.name}')\n",
    "            pruned_nodes_attr[(layer, head)] = node_attr[layer, head]\n",
    "            \n",
    "            # REMOVING QKV\n",
    "            qkv_nodes = find_attn_node_qkv(exp, layer, head)\n",
    "            for node in qkv_nodes:\n",
    "                remove_node(exp, node)\n",
    "    return pruned_nodes_attr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a64c0d",
   "metadata": {},
   "source": [
    "# Show resulting graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c560c9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from acdc.TLACDCInterpNode import TLACDCInterpNode\n",
    "import pygraphviz as pgv\n",
    "from pathlib import Path\n",
    "\n",
    "def get_node_name(node: TLACDCInterpNode, show_full_index=True):\n",
    "    \"\"\"Node name for use in pretty graphs\"\"\"\n",
    "\n",
    "    if not show_full_index:\n",
    "        name = \"\"\n",
    "        qkv_substrings = [f\"hook_{letter}\" for letter in [\"q\", \"k\", \"v\"]]\n",
    "        qkv_input_substrings = [f\"hook_{letter}_input\" for letter in [\"q\", \"k\", \"v\"]]\n",
    "\n",
    "        # Handle embedz\n",
    "        if \"resid_pre\" in node.name:\n",
    "            assert \"0\" in node.name and not any([str(i) in node.name for i in range(1, 10)])\n",
    "            name += \"embed\"\n",
    "            if len(node.index.hashable_tuple) > 2:\n",
    "                name += f\"_[{node.index.hashable_tuple[2]}]\"\n",
    "            return name\n",
    "\n",
    "        elif \"embed\" in node.name:\n",
    "            name = \"pos_embeds\" if \"pos\" in node.name else \"token_embeds\"\n",
    "\n",
    "        # Handle q_input and hook_q etc\n",
    "        elif any([node.name.endswith(qkv_input_substring) for qkv_input_substring in qkv_input_substrings]):\n",
    "            relevant_letter = None\n",
    "            for letter, qkv_substring in zip([\"q\", \"k\", \"v\"], qkv_substrings):\n",
    "                if qkv_substring in node.name:\n",
    "                    assert relevant_letter is None\n",
    "                    relevant_letter = letter\n",
    "            name += \"a\" + node.name.split(\".\")[1] + \".\" + str(node.index.hashable_tuple[2]) + \"_\" + relevant_letter\n",
    "\n",
    "        # Handle attention hook_result\n",
    "        elif \"hook_result\" in node.name or any([qkv_substring in node.name for qkv_substring in qkv_substrings]):\n",
    "            name = \"a\" + node.name.split(\".\")[1] + \".\" + str(node.index.hashable_tuple[2])\n",
    "\n",
    "        # Handle MLPs\n",
    "        elif node.name.endswith(\"resid_mid\"):\n",
    "            raise ValueError(\"We removed resid_mid annotations. Call these mlp_in now.\")\n",
    "        elif node.name.endswith(\"mlp_out\") or node.name.endswith(\"mlp_in\"):\n",
    "            name = \"m\" + node.name.split(\".\")[1]\n",
    "\n",
    "        # Handle resid_post\n",
    "        elif \"resid_post\" in node.name:\n",
    "            name += \"resid_post\"\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unrecognized node name {node.name}\")\n",
    "\n",
    "    else:\n",
    "        \n",
    "        name = node.name + str(node.index.graphviz_index(use_actual_colon=True))\n",
    "\n",
    "    return \"<\" + name + \">\"\n",
    "\n",
    "def generate_random_color(colorscheme: str) -> str:\n",
    "    \"\"\"\n",
    "    https://stackoverflow.com/questions/28999287/generate-random-colors-rgb\n",
    "    \"\"\"\n",
    "    def rgb2hex(rgb):\n",
    "        \"\"\"\n",
    "        https://stackoverflow.com/questions/3380726/converting-an-rgb-color-tuple-to-a-hexidecimal-string\n",
    "        \"\"\"\n",
    "        return \"#{:02x}{:02x}{:02x}\".format(rgb[0], rgb[1], rgb[2])\n",
    "\n",
    "    return rgb2hex((np.random.randint(0, 256), np.random.randint(0, 256), np.random.randint(0, 256)))\n",
    "\n",
    "def build_colorscheme(correspondence, colorscheme: str = \"Pastel2\", show_full_index=True) -> Dict[str, str]:\n",
    "    colors = {}\n",
    "    for node in correspondence.nodes():\n",
    "        colors[get_node_name(node, show_full_index=show_full_index)] = generate_random_color(colorscheme)\n",
    "    return colors\n",
    "\n",
    "def show(\n",
    "    correspondence: TLACDCInterpNode,\n",
    "    fname=None,\n",
    "    colorscheme: Union[Dict, str] = \"Pastel2\",\n",
    "    minimum_penwidth: float = 0.3,\n",
    "    show_full_index: bool = False,\n",
    "    remove_self_loops: bool = True,\n",
    "    remove_qkv: bool = True,\n",
    "    layout: str=\"dot\",\n",
    "    edge_type_colouring: bool = False,\n",
    "    show_placeholders: bool = False,\n",
    "    seed: Optional[int] = None\n",
    "):\n",
    "    g = pgv.AGraph(directed=True, bgcolor=\"transparent\", overlap=\"false\", splines=\"true\", layout=layout)\n",
    "\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    groups = {}\n",
    "    if isinstance(colorscheme, str):\n",
    "        colors = build_colorscheme(correspondence, colorscheme, show_full_index=show_full_index)\n",
    "    else:\n",
    "        colors = colorscheme\n",
    "        for name, color in colors.items():\n",
    "            if color not in groups:\n",
    "                groups[color] = [name]\n",
    "            else:\n",
    "                groups[color].append(name)\n",
    "\n",
    "    node_pos = {}\n",
    "    if fname is not None:\n",
    "        base_fname = \".\".join(str(fname).split(\".\")[:-1])\n",
    "\n",
    "        base_path = Path(base_fname)\n",
    "        fpath = base_path / \"layout.gv\"\n",
    "        if fpath.exists():\n",
    "            g_pos = pgv.AGraph()\n",
    "            g_pos.read(fpath)\n",
    "            for node in g_pos.nodes():\n",
    "                node_pos[node.name] = node.attr[\"pos\"]\n",
    "    \n",
    "    for child_hook_name in correspondence.edges:\n",
    "        for child_index in correspondence.edges[child_hook_name]:\n",
    "            for parent_hook_name in correspondence.edges[child_hook_name][child_index]:\n",
    "                for parent_index in correspondence.edges[child_hook_name][child_index][parent_hook_name]:\n",
    "                    edge = correspondence.edges[child_hook_name][child_index][parent_hook_name][parent_index]\n",
    "\n",
    "                    parent = correspondence.graph[parent_hook_name][parent_index]\n",
    "                    child = correspondence.graph[child_hook_name][child_index]\n",
    "\n",
    "                    parent_name = get_node_name(parent, show_full_index=show_full_index)\n",
    "                    child_name = get_node_name(child, show_full_index=show_full_index)\n",
    "                    \n",
    "                    if remove_qkv:\n",
    "                        if any(qkv in child_name or qkv in parent_name for qkv in ['_q_', '_k_', '_v_']):\n",
    "                            continue\n",
    "                        parent_name = parent_name.replace(\"_q>\", \">\").replace(\"_k>\", \">\").replace(\"_v>\", \">\")\n",
    "                        child_name = child_name.replace(\"_q>\", \">\").replace(\"_k>\", \">\").replace(\"_v>\", \">\")\n",
    "\n",
    "                    if remove_self_loops and parent_name == child_name:\n",
    "                        # Important this go after the qkv removal\n",
    "                        continue\n",
    "                    \n",
    "                    if edge.present and (edge.edge_type != EdgeType.PLACEHOLDER or show_placeholders):\n",
    "                        #print(f'Edge from {parent_name=} to {child_name=}')\n",
    "                        for node_name in [parent_name, child_name]:\n",
    "                            maybe_pos = {}\n",
    "                            if node_name in node_pos:\n",
    "                                maybe_pos[\"pos\"] = node_pos[node_name]\n",
    "                            g.add_node(\n",
    "                                node_name,\n",
    "                                fillcolor=colors[node_name],\n",
    "                                color=\"black\",\n",
    "                                style=\"filled, rounded\",\n",
    "                                shape=\"box\",\n",
    "                                fontname=\"Helvetica\",\n",
    "                                **maybe_pos,\n",
    "                            )\n",
    "                        \n",
    "                        g.add_edge(\n",
    "                            parent_name,\n",
    "                            child_name,\n",
    "                            penwidth=str(minimum_penwidth * 2),\n",
    "                            color=colors[parent_name] if not edge_type_colouring else EDGE_TYPE_COLORS[edge.edge_type.value],\n",
    "                        )\n",
    "    if fname is not None:\n",
    "        base_fname = \".\".join(str(fname).split(\".\")[:-1])\n",
    "\n",
    "        base_path = Path(base_fname)\n",
    "        base_path.mkdir(exist_ok=True)\n",
    "        for k, s in groups.items():\n",
    "            g2 = pgv.AGraph(directed=True, bgcolor=\"transparent\", overlap=\"false\", splines=\"true\", layout=\"neato\")\n",
    "            for node_name in s:\n",
    "                g2.add_node(\n",
    "                    node_name,\n",
    "                    style=\"filled, rounded\",\n",
    "                    shape=\"box\",\n",
    "                )\n",
    "            for i in range(len(s)):\n",
    "                for j in range(i + 1, len(s)):\n",
    "                    g2.add_edge(s[i], s[j], style=\"invis\", weight=200)\n",
    "            g2.write(path=base_path / f\"{k}.gv\")\n",
    "\n",
    "        g.write(path=base_fname + \".gv\")\n",
    "\n",
    "        if not fname.endswith(\".gv\"): # turn the .gv file into a .png file\n",
    "            g.draw(path=fname, prog=\"dot\")\n",
    "\n",
    "    return g\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf81ab6e",
   "metadata": {},
   "source": [
    "# Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d02f42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:cache_all is deprecated and will eventually be removed, use add_caching_hooks or run_with_cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln_final.hook_normalized\n",
      "ln_final.hook_scale\n",
      "blocks.11.hook_resid_post\n",
      "blocks.11.hook_mlp_out\n",
      "blocks.11.mlp.hook_post\n",
      "blocks.11.mlp.hook_pre\n",
      "blocks.11.ln2.hook_normalized\n",
      "blocks.11.ln2.hook_scale\n",
      "blocks.11.hook_mlp_in\n",
      "blocks.11.hook_resid_mid\n",
      "blocks.11.hook_attn_out\n",
      "blocks.11.attn.hook_result\n",
      "blocks.11.attn.hook_z\n",
      "blocks.11.attn.hook_pattern\n",
      "blocks.11.attn.hook_attn_scores\n",
      "blocks.11.attn.hook_v\n",
      "blocks.11.attn.hook_k\n",
      "blocks.11.attn.hook_q\n",
      "blocks.11.ln1.hook_normalized\n",
      "blocks.11.ln1.hook_scale\n",
      "blocks.11.hook_v_input\n",
      "blocks.11.hook_k_input\n",
      "blocks.11.hook_q_input\n",
      "blocks.11.hook_resid_pre\n",
      "blocks.10.hook_resid_post\n",
      "blocks.10.hook_mlp_out\n",
      "blocks.10.mlp.hook_post\n",
      "blocks.10.mlp.hook_pre\n",
      "blocks.10.ln2.hook_normalized\n",
      "blocks.10.ln2.hook_scale\n",
      "blocks.10.hook_mlp_in\n",
      "blocks.10.hook_resid_mid\n",
      "blocks.10.hook_attn_out\n",
      "blocks.10.attn.hook_result\n",
      "blocks.10.attn.hook_z\n",
      "blocks.10.attn.hook_pattern\n",
      "blocks.10.attn.hook_attn_scores\n",
      "blocks.10.attn.hook_v\n",
      "blocks.10.attn.hook_k\n",
      "blocks.10.attn.hook_q\n",
      "blocks.10.ln1.hook_normalized\n",
      "blocks.10.ln1.hook_scale\n",
      "blocks.10.hook_v_input\n",
      "blocks.10.hook_k_input\n",
      "blocks.10.hook_q_input\n",
      "blocks.10.hook_resid_pre\n",
      "blocks.9.hook_resid_post\n",
      "blocks.9.hook_mlp_out\n",
      "blocks.9.mlp.hook_post\n",
      "blocks.9.mlp.hook_pre\n",
      "blocks.9.ln2.hook_normalized\n",
      "blocks.9.ln2.hook_scale\n",
      "blocks.9.hook_mlp_in\n",
      "blocks.9.hook_resid_mid\n",
      "blocks.9.hook_attn_out\n",
      "blocks.9.attn.hook_result\n",
      "blocks.9.attn.hook_z\n",
      "blocks.9.attn.hook_pattern\n",
      "blocks.9.attn.hook_attn_scores\n",
      "blocks.9.attn.hook_v\n",
      "blocks.9.attn.hook_k\n",
      "blocks.9.attn.hook_q\n",
      "blocks.9.ln1.hook_normalized\n",
      "blocks.9.ln1.hook_scale\n",
      "blocks.9.hook_v_input\n",
      "blocks.9.hook_k_input\n",
      "blocks.9.hook_q_input\n",
      "blocks.9.hook_resid_pre\n",
      "blocks.8.hook_resid_post\n",
      "blocks.8.hook_mlp_out\n",
      "blocks.8.mlp.hook_post\n",
      "blocks.8.mlp.hook_pre\n",
      "blocks.8.ln2.hook_normalized\n",
      "blocks.8.ln2.hook_scale\n",
      "blocks.8.hook_mlp_in\n",
      "blocks.8.hook_resid_mid\n",
      "blocks.8.hook_attn_out\n",
      "blocks.8.attn.hook_result\n",
      "blocks.8.attn.hook_z\n",
      "blocks.8.attn.hook_pattern\n",
      "blocks.8.attn.hook_attn_scores\n",
      "blocks.8.attn.hook_v\n",
      "blocks.8.attn.hook_k\n",
      "blocks.8.attn.hook_q\n",
      "blocks.8.ln1.hook_normalized\n",
      "blocks.8.ln1.hook_scale\n",
      "blocks.8.hook_v_input\n",
      "blocks.8.hook_k_input\n",
      "blocks.8.hook_q_input\n",
      "blocks.8.hook_resid_pre\n",
      "blocks.7.hook_resid_post\n",
      "blocks.7.hook_mlp_out\n",
      "blocks.7.mlp.hook_post\n",
      "blocks.7.mlp.hook_pre\n",
      "blocks.7.ln2.hook_normalized\n",
      "blocks.7.ln2.hook_scale\n",
      "blocks.7.hook_mlp_in\n",
      "blocks.7.hook_resid_mid\n",
      "blocks.7.hook_attn_out\n",
      "blocks.7.attn.hook_result\n",
      "blocks.7.attn.hook_z\n",
      "blocks.7.attn.hook_pattern\n",
      "blocks.7.attn.hook_attn_scores\n",
      "blocks.7.attn.hook_v\n",
      "blocks.7.attn.hook_k\n",
      "blocks.7.attn.hook_q\n",
      "blocks.7.ln1.hook_normalized\n",
      "blocks.7.ln1.hook_scale\n",
      "blocks.7.hook_v_input\n",
      "blocks.7.hook_k_input\n",
      "blocks.7.hook_q_input\n",
      "blocks.7.hook_resid_pre\n",
      "blocks.6.hook_resid_post\n",
      "blocks.6.hook_mlp_out\n",
      "blocks.6.mlp.hook_post\n",
      "blocks.6.mlp.hook_pre\n",
      "blocks.6.ln2.hook_normalized\n",
      "blocks.6.ln2.hook_scale\n",
      "blocks.6.hook_mlp_in\n",
      "blocks.6.hook_resid_mid\n",
      "blocks.6.hook_attn_out\n",
      "blocks.6.attn.hook_result\n",
      "blocks.6.attn.hook_z\n",
      "blocks.6.attn.hook_pattern\n",
      "blocks.6.attn.hook_attn_scores\n",
      "blocks.6.attn.hook_v\n",
      "blocks.6.attn.hook_k\n",
      "blocks.6.attn.hook_q\n",
      "blocks.6.ln1.hook_normalized\n",
      "blocks.6.ln1.hook_scale\n",
      "blocks.6.hook_v_input\n",
      "blocks.6.hook_k_input\n",
      "blocks.6.hook_q_input\n",
      "blocks.6.hook_resid_pre\n",
      "blocks.5.hook_resid_post\n",
      "blocks.5.hook_mlp_out\n",
      "blocks.5.mlp.hook_post\n",
      "blocks.5.mlp.hook_pre\n",
      "blocks.5.ln2.hook_normalized\n",
      "blocks.5.ln2.hook_scale\n",
      "blocks.5.hook_mlp_in\n",
      "blocks.5.hook_resid_mid\n",
      "blocks.5.hook_attn_out\n",
      "blocks.5.attn.hook_result\n",
      "blocks.5.attn.hook_z\n",
      "blocks.5.attn.hook_pattern\n",
      "blocks.5.attn.hook_attn_scores\n",
      "blocks.5.attn.hook_v\n",
      "blocks.5.attn.hook_k\n",
      "blocks.5.attn.hook_q\n",
      "blocks.5.ln1.hook_normalized\n",
      "blocks.5.ln1.hook_scale\n",
      "blocks.5.hook_v_input\n",
      "blocks.5.hook_k_input\n",
      "blocks.5.hook_q_input\n",
      "blocks.5.hook_resid_pre\n",
      "blocks.4.hook_resid_post\n",
      "blocks.4.hook_mlp_out\n",
      "blocks.4.mlp.hook_post\n",
      "blocks.4.mlp.hook_pre\n",
      "blocks.4.ln2.hook_normalized\n",
      "blocks.4.ln2.hook_scale\n",
      "blocks.4.hook_mlp_in\n",
      "blocks.4.hook_resid_mid\n",
      "blocks.4.hook_attn_out\n",
      "blocks.4.attn.hook_result\n",
      "blocks.4.attn.hook_z\n",
      "blocks.4.attn.hook_pattern\n",
      "blocks.4.attn.hook_attn_scores\n",
      "blocks.4.attn.hook_v\n",
      "blocks.4.attn.hook_k\n",
      "blocks.4.attn.hook_q\n",
      "blocks.4.ln1.hook_normalized\n",
      "blocks.4.ln1.hook_scale\n",
      "blocks.4.hook_v_input\n",
      "blocks.4.hook_k_input\n",
      "blocks.4.hook_q_input\n",
      "blocks.4.hook_resid_pre\n",
      "blocks.3.hook_resid_post\n",
      "blocks.3.hook_mlp_out\n",
      "blocks.3.mlp.hook_post\n",
      "blocks.3.mlp.hook_pre\n",
      "blocks.3.ln2.hook_normalized\n",
      "blocks.3.ln2.hook_scale\n",
      "blocks.3.hook_mlp_in\n",
      "blocks.3.hook_resid_mid\n",
      "blocks.3.hook_attn_out\n",
      "blocks.3.attn.hook_result\n",
      "blocks.3.attn.hook_z\n",
      "blocks.3.attn.hook_pattern\n",
      "blocks.3.attn.hook_attn_scores\n",
      "blocks.3.attn.hook_v\n",
      "blocks.3.attn.hook_k\n",
      "blocks.3.attn.hook_q\n",
      "blocks.3.ln1.hook_normalized\n",
      "blocks.3.ln1.hook_scale\n",
      "blocks.3.hook_v_input\n",
      "blocks.3.hook_k_input\n",
      "blocks.3.hook_q_input\n",
      "blocks.3.hook_resid_pre\n",
      "blocks.2.hook_resid_post\n",
      "blocks.2.hook_mlp_out\n",
      "blocks.2.mlp.hook_post\n",
      "blocks.2.mlp.hook_pre\n",
      "blocks.2.ln2.hook_normalized\n",
      "blocks.2.ln2.hook_scale\n",
      "blocks.2.hook_mlp_in\n",
      "blocks.2.hook_resid_mid\n",
      "blocks.2.hook_attn_out\n",
      "blocks.2.attn.hook_result\n",
      "blocks.2.attn.hook_z\n",
      "blocks.2.attn.hook_pattern\n",
      "blocks.2.attn.hook_attn_scores\n",
      "blocks.2.attn.hook_v\n",
      "blocks.2.attn.hook_k\n",
      "blocks.2.attn.hook_q\n",
      "blocks.2.ln1.hook_normalized\n",
      "blocks.2.ln1.hook_scale\n",
      "blocks.2.hook_v_input\n",
      "blocks.2.hook_k_input\n",
      "blocks.2.hook_q_input\n",
      "blocks.2.hook_resid_pre\n",
      "blocks.1.hook_resid_post\n",
      "blocks.1.hook_mlp_out\n",
      "blocks.1.mlp.hook_post\n",
      "blocks.1.mlp.hook_pre\n",
      "blocks.1.ln2.hook_normalized\n",
      "blocks.1.ln2.hook_scale\n",
      "blocks.1.hook_mlp_in\n",
      "blocks.1.hook_resid_mid\n",
      "blocks.1.hook_attn_out\n",
      "blocks.1.attn.hook_result\n",
      "blocks.1.attn.hook_z\n",
      "blocks.1.attn.hook_pattern\n",
      "blocks.1.attn.hook_attn_scores\n",
      "blocks.1.attn.hook_v\n",
      "blocks.1.attn.hook_k\n",
      "blocks.1.attn.hook_q\n",
      "blocks.1.ln1.hook_normalized\n",
      "blocks.1.ln1.hook_scale\n",
      "blocks.1.hook_v_input\n",
      "blocks.1.hook_k_input\n",
      "blocks.1.hook_q_input\n",
      "blocks.1.hook_resid_pre\n",
      "blocks.0.hook_resid_post\n",
      "blocks.0.hook_mlp_out\n",
      "blocks.0.mlp.hook_post\n",
      "blocks.0.mlp.hook_pre\n",
      "blocks.0.ln2.hook_normalized\n",
      "blocks.0.ln2.hook_scale\n",
      "blocks.0.hook_mlp_in\n",
      "blocks.0.hook_resid_mid\n",
      "blocks.0.hook_attn_out\n",
      "blocks.0.attn.hook_result\n",
      "blocks.0.attn.hook_z\n",
      "blocks.0.attn.hook_pattern\n",
      "blocks.0.attn.hook_attn_scores\n",
      "blocks.0.attn.hook_v\n",
      "blocks.0.attn.hook_k\n",
      "blocks.0.attn.hook_q\n",
      "blocks.0.ln1.hook_normalized\n",
      "blocks.0.ln1.hook_scale\n",
      "blocks.0.hook_v_input\n",
      "blocks.0.hook_k_input\n",
      "blocks.0.hook_q_input\n",
      "blocks.0.hook_resid_pre\n",
      "hook_pos_embed\n",
      "hook_embed\n",
      "self.current_node=TLACDCInterpNode(blocks.11.hook_resid_post, [:])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "makedirs() got an unexpected keyword argument 'exists_ok'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m start_thresh_time \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Set up model\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Set up experiment\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m exp \u001b[38;5;241m=\u001b[39m \u001b[43mTLACDCExperiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclean_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mref_ds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorr_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnegative_ioi_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mzero_ablation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhook_verbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSetting up graph\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Set up computational graph\u001b[39;00m\n",
      "File \u001b[0;32m~/acdcpp/Automatic-Circuit-Discovery/acdc/TLACDCExperiment.py:132\u001b[0m, in \u001b[0;36mTLACDCExperiment.__init__\u001b[0;34m(self, model, ds, ref_ds, threshold, metric, run_name, second_metric, verbose, hook_verbose, parallel_hypotheses, remove_redundant, online_cache_cpu, corrupted_cache_cpu, zero_ablation, abs_value_threshold, show_full_index, using_wandb, wandb_entity_name, wandb_project_name, wandb_run_name, wandb_group_name, wandb_notes, wandb_dir, wandb_mode, use_pos_embed, skip_edges, add_sender_hooks, add_receiver_hooks, indices_mode, names_mode, wandb_config, early_exit)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorrupted_cache_cpu \u001b[38;5;241m=\u001b[39m corrupted_cache_cpu\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_name \u001b[38;5;241m=\u001b[39m run_name\n\u001b[0;32m--> 132\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mims/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrun_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mthreshold\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexists_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m zero_ablation:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mref_ds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: makedirs() got an unexpected keyword argument 'exists_ok'"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "THRESHOLDS = [0.2, 0.3, 0.4, 0.5]\n",
    "run_name = 'ioi_thresh_run'\n",
    "pruned_nodes_per_thresh = {}\n",
    "for threshold in THRESHOLDS:\n",
    "    start_thresh_time = time()\n",
    "    # Set up model\n",
    "    # Set up experiment\n",
    "    exp = TLACDCExperiment(\n",
    "        model=model,\n",
    "        threshold=threshold,\n",
    "        run_name=run_name,\n",
    "        ds=clean_dataset.toks,\n",
    "        ref_ds=corr_dataset.toks,\n",
    "        metric=negative_ioi_metric,\n",
    "        zero_ablation=True,\n",
    "        hook_verbose=False\n",
    "    )\n",
    "    print('Setting up graph')\n",
    "    # Set up computational graph\n",
    "    exp.model.reset_hooks()\n",
    "    exp.setup_model_hooks(\n",
    "        add_sender_hooks=True,\n",
    "        add_receiver_hooks=True,\n",
    "        doing_acdc_runs=False,\n",
    "    )\n",
    "    exp_time = time()\n",
    "    print(f'Time to set up exp: {exp_time - start_thresh_time}')\n",
    "    for _ in range(10):\n",
    "        pruned_nodes_attr = acdc_nodes(\n",
    "            model=exp.model,\n",
    "            clean_input=clean_dataset.toks,\n",
    "            corrupted_input=corr_dataset.toks,\n",
    "            metric=ioi_metric,\n",
    "            threshold=threshold,\n",
    "            exp=exp,\n",
    "            attr_absolute_val=True,\n",
    "        ) \n",
    "        t.cuda.empty_cache()\n",
    "    acdcpp_time = time()\n",
    "    print(f'ACDC++ time: {acdcpp_time - exp_time}')\n",
    "    pruned_nodes_per_thresh[threshold] = pruned_nodes_attr\n",
    "    show(exp.corr, fname=f'ims/{run_name}/thresh{threshold}_before_acdc.png')\n",
    "    \n",
    "    start_acdc_time = time()\n",
    "    for _ in range(MAX_EPOCHS):\n",
    "        exp.step(testing=False)\n",
    "    print(f'ACDC Time: {time() - start_acdc_time}')\n",
    "    show(exp.corr, fname=f'ims/{run_name}/thresh{threshold}_after_acdc.png')\n",
    "    del exp\n",
    "    t.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b08e9e-a140-4a97-a309-3210cc8f8ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
