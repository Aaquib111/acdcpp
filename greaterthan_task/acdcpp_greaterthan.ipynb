{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('Automatic-Circuit-Discovery/')\n",
    "\n",
    "from acdc.TLACDCInterpNode import TLACDCInterpNode\n",
    "from acdc.acdc_utils import EdgeType\n",
    "import numpy as np\n",
    "\n",
    "import pygraphviz as pgv\n",
    "from pathlib import Path\n",
    "\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "from typing import Union, Dict, Optional\n",
    "\n",
    "\n",
    "def get_node_name(node: TLACDCInterpNode, show_full_index=True):\n",
    "    \"\"\"Node name for use in pretty graphs\"\"\"\n",
    "\n",
    "    if not show_full_index:\n",
    "        name = \"\"\n",
    "        qkv_substrings = [f\"hook_{letter}\" for letter in [\"q\", \"k\", \"v\"]]\n",
    "        qkv_input_substrings = [f\"hook_{letter}_input\" for letter in [\"q\", \"k\", \"v\"]]\n",
    "\n",
    "        # Handle embedz\n",
    "        if \"resid_pre\" in node.name:\n",
    "            assert \"0\" in node.name and not any([str(i) in node.name for i in range(1, 10)])\n",
    "            name += \"embed\"\n",
    "            if len(node.index.hashable_tuple) > 2:\n",
    "                name += f\"_[{node.index.hashable_tuple[2]}]\"\n",
    "            return name\n",
    "\n",
    "        elif \"embed\" in node.name:\n",
    "            name = \"pos_embeds\" if \"pos\" in node.name else \"token_embeds\"\n",
    "\n",
    "        # Handle q_input and hook_q etc\n",
    "        elif any([node.name.endswith(qkv_input_substring) for qkv_input_substring in qkv_input_substrings]):\n",
    "            relevant_letter = None\n",
    "            for letter, qkv_substring in zip([\"q\", \"k\", \"v\"], qkv_substrings):\n",
    "                if qkv_substring in node.name:\n",
    "                    assert relevant_letter is None\n",
    "                    relevant_letter = letter\n",
    "            name += \"a\" + node.name.split(\".\")[1] + \".\" + str(node.index.hashable_tuple[2]) + \"_\" + relevant_letter\n",
    "\n",
    "        # Handle attention hook_result\n",
    "        elif \"hook_result\" in node.name or any([qkv_substring in node.name for qkv_substring in qkv_substrings]):\n",
    "            name = \"a\" + node.name.split(\".\")[1] + \".\" + str(node.index.hashable_tuple[2])\n",
    "\n",
    "        # Handle MLPs\n",
    "        elif node.name.endswith(\"resid_mid\"):\n",
    "            raise ValueError(\"We removed resid_mid annotations. Call these mlp_in now.\")\n",
    "        elif node.name.endswith(\"mlp_out\") or node.name.endswith(\"mlp_in\"):\n",
    "            name = \"m\" + node.name.split(\".\")[1]\n",
    "\n",
    "        # Handle resid_post\n",
    "        elif \"resid_post\" in node.name:\n",
    "            name += \"resid_post\"\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unrecognized node name {node.name}\")\n",
    "\n",
    "    else:\n",
    "        \n",
    "        name = node.name + str(node.index.graphviz_index(use_actual_colon=True))\n",
    "\n",
    "    return \"<\" + name + \">\"\n",
    "\n",
    "def generate_random_color(colorscheme: str) -> str:\n",
    "    \"\"\"\n",
    "    https://stackoverflow.com/questions/28999287/generate-random-colors-rgb\n",
    "    \"\"\"\n",
    "    def rgb2hex(rgb):\n",
    "        \"\"\"\n",
    "        https://stackoverflow.com/questions/3380726/converting-an-rgb-color-tuple-to-a-hexidecimal-string\n",
    "        \"\"\"\n",
    "        return \"#{:02x}{:02x}{:02x}\".format(rgb[0], rgb[1], rgb[2])\n",
    "\n",
    "    return rgb2hex((np.random.randint(0, 256), np.random.randint(0, 256), np.random.randint(0, 256)))\n",
    "\n",
    "def build_colorscheme(correspondence, colorscheme: str = \"Pastel2\", show_full_index=True) -> Dict[str, str]:\n",
    "    colors = {}\n",
    "    for node in correspondence.nodes():\n",
    "        colors[get_node_name(node, show_full_index=show_full_index)] = generate_random_color(colorscheme)\n",
    "    return colors\n",
    "\n",
    "def show(\n",
    "    correspondence: TLACDCInterpNode,\n",
    "    fname=None,\n",
    "    colorscheme: Union[Dict, str] = \"Pastel2\",\n",
    "    minimum_penwidth: float = 0.3,\n",
    "    show_full_index: bool = False,\n",
    "    remove_self_loops: bool = True,\n",
    "    remove_qkv: bool = True,\n",
    "    layout: str=\"dot\",\n",
    "    edge_type_colouring: bool = False,\n",
    "    show_placeholders: bool = False,\n",
    "    seed: Optional[int] = None\n",
    "):\n",
    "    g = pgv.AGraph(directed=True, bgcolor=\"transparent\", overlap=\"false\", splines=\"true\", layout=layout)\n",
    "\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    groups = {}\n",
    "    if isinstance(colorscheme, str):\n",
    "        colors = build_colorscheme(correspondence, colorscheme, show_full_index=show_full_index)\n",
    "    else:\n",
    "        colors = colorscheme\n",
    "        for name, color in colors.items():\n",
    "            if color not in groups:\n",
    "                groups[color] = [name]\n",
    "            else:\n",
    "                groups[color].append(name)\n",
    "\n",
    "    node_pos = {}\n",
    "    if fname is not None:\n",
    "        base_fname = \".\".join(str(fname).split(\".\")[:-1])\n",
    "\n",
    "        base_path = Path(base_fname)\n",
    "        fpath = base_path / \"layout.gv\"\n",
    "        if fpath.exists():\n",
    "            g_pos = pgv.AGraph()\n",
    "            g_pos.read(fpath)\n",
    "            for node in g_pos.nodes():\n",
    "                node_pos[node.name] = node.attr[\"pos\"]\n",
    "    \n",
    "    for child_hook_name in correspondence.edges:\n",
    "        for child_index in correspondence.edges[child_hook_name]:\n",
    "            for parent_hook_name in correspondence.edges[child_hook_name][child_index]:\n",
    "                for parent_index in correspondence.edges[child_hook_name][child_index][parent_hook_name]:\n",
    "                    edge = correspondence.edges[child_hook_name][child_index][parent_hook_name][parent_index]\n",
    "\n",
    "                    parent = correspondence.graph[parent_hook_name][parent_index]\n",
    "                    child = correspondence.graph[child_hook_name][child_index]\n",
    "\n",
    "                    parent_name = get_node_name(parent, show_full_index=show_full_index)\n",
    "                    child_name = get_node_name(child, show_full_index=show_full_index)\n",
    "                    \n",
    "                    if remove_qkv:\n",
    "                        if any(qkv in child_name or qkv in parent_name for qkv in ['_q_', '_k_', '_v_']):\n",
    "                            continue\n",
    "                        parent_name = parent_name.replace(\"_q>\", \">\").replace(\"_k>\", \">\").replace(\"_v>\", \">\")\n",
    "                        child_name = child_name.replace(\"_q>\", \">\").replace(\"_k>\", \">\").replace(\"_v>\", \">\")\n",
    "\n",
    "                    if remove_self_loops and parent_name == child_name:\n",
    "                        # Important this go after the qkv removal\n",
    "                        continue\n",
    "                    \n",
    "                    if edge.present and (edge.edge_type != EdgeType.PLACEHOLDER or show_placeholders):\n",
    "                        #print(f'Edge from {parent_name=} to {child_name=}')\n",
    "                        for node_name in [parent_name, child_name]:\n",
    "                            maybe_pos = {}\n",
    "                            if node_name in node_pos:\n",
    "                                maybe_pos[\"pos\"] = node_pos[node_name]\n",
    "                            g.add_node(\n",
    "                                node_name,\n",
    "                                fillcolor=colors[node_name],\n",
    "                                color=\"black\",\n",
    "                                style=\"filled, rounded\",\n",
    "                                shape=\"box\",\n",
    "                                fontname=\"Helvetica\",\n",
    "                                **maybe_pos,\n",
    "                            )\n",
    "                        \n",
    "                        g.add_edge(\n",
    "                            parent_name,\n",
    "                            child_name,\n",
    "                            penwidth=str(minimum_penwidth * 2),\n",
    "                            color=colors[parent_name],\n",
    "                        )\n",
    "    if fname is not None:\n",
    "        base_fname = \".\".join(str(fname).split(\".\")[:-1])\n",
    "\n",
    "        base_path = Path(base_fname)\n",
    "        base_path.mkdir(exist_ok=True)\n",
    "        for k, s in groups.items():\n",
    "            g2 = pgv.AGraph(directed=True, bgcolor=\"transparent\", overlap=\"false\", splines=\"true\", layout=\"neato\")\n",
    "            for node_name in s:\n",
    "                g2.add_node(\n",
    "                    node_name,\n",
    "                    style=\"filled, rounded\",\n",
    "                    shape=\"box\",\n",
    "                )\n",
    "            for i in range(len(s)):\n",
    "                for j in range(i + 1, len(s)):\n",
    "                    g2.add_edge(s[i], s[j], style=\"invis\", weight=200)\n",
    "            g2.write(path=base_path / f\"{k}.gv\")\n",
    "\n",
    "        g.write(path=base_fname + \".gv\")\n",
    "\n",
    "        if not fname.endswith(\".gv\"): # turn the .gv file into a .png file\n",
    "            g.draw(path=fname, prog=\"dot\")\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('Automatic-Circuit-Discovery/')\n",
    "\n",
    "from acdc.TLACDCExperiment import TLACDCExperiment\n",
    "from acdc.acdc_utils import TorchIndex, EdgeType\n",
    "import torch as t\n",
    "from torch import Tensor\n",
    "import einops\n",
    "import itertools\n",
    "\n",
    "from transformer_lens import HookedTransformer, ActivationCache\n",
    "\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "from jaxtyping import Bool\n",
    "from typing import Callable, Tuple \n",
    "\n",
    "\n",
    "def remove_redundant_node(exp, node, safe=True, allow_fails=True):\n",
    "        if safe:\n",
    "            for parent_name in exp.corr.edges[node.name][node.index]:\n",
    "                for parent_index in exp.corr.edges[node.name][node.index][parent_name]:\n",
    "                    if exp.corr.edges[node.name][node.index][parent_name][parent_index].present:\n",
    "                        raise Exception(f\"You should not be removing a node that is still used by another node {node} {(parent_name, parent_index)}\")\n",
    "\n",
    "        bfs = [node]\n",
    "        bfs_idx = 0\n",
    "\n",
    "        while bfs_idx < len(bfs):\n",
    "            cur_node = bfs[bfs_idx]\n",
    "            bfs_idx += 1\n",
    "\n",
    "            children = exp.corr.graph[cur_node.name][cur_node.index].children\n",
    "\n",
    "            for child_node in children:\n",
    "                if not cur_node.index in exp.corr.edges[child_node.name][child_node.index][cur_node.name]:\n",
    "                    #print(f'\\t CANT remove edge {cur_node.name}, {cur_node.index} <-> {child_node.name}, {child_node.index}')\n",
    "                    continue\n",
    "                    \n",
    "                try:\n",
    "                    #print(f'\\t Removing edge {cur_node.name}, {cur_node.index} <-> {child_node.name}, {child_node.index}')\n",
    "                    exp.corr.remove_edge(\n",
    "                        child_node.name, child_node.index, cur_node.name, cur_node.index\n",
    "                    )\n",
    "                except KeyError as e:\n",
    "                    print(\"Got an error\", e)\n",
    "                    if allow_fails:\n",
    "                        continue\n",
    "                    else:\n",
    "                        raise e\n",
    "\n",
    "                remove_this = True\n",
    "                for parent_of_child_name in exp.corr.edges[child_node.name][child_node.index]:\n",
    "                    for parent_of_child_index in exp.corr.edges[child_node.name][child_node.index][parent_of_child_name]:\n",
    "                        if exp.corr.edges[child_node.name][child_node.index][parent_of_child_name][parent_of_child_index].present:\n",
    "                            remove_this = False\n",
    "                            break\n",
    "                    if not remove_this:\n",
    "                        break\n",
    "\n",
    "                if remove_this and child_node not in bfs:\n",
    "                    bfs.append(child_node)\n",
    "\n",
    "def remove_node(exp, node):\n",
    "    '''\n",
    "        Method that removes node from model. Assumes children point towards\n",
    "        the end of the residual stream and parents point towards the beginning.\n",
    "\n",
    "        exp: A TLACDCExperiment object with a reverse top sorted graph\n",
    "        node: A TLACDCInterpNode describing the node to remove\n",
    "        root: Initally the first node in the graph\n",
    "    '''\n",
    "    #Removing all edges pointing to the node\n",
    "    remove_edges = []\n",
    "    for p_name in exp.corr.edges[node.name][node.index]:\n",
    "        for p_idx in exp.corr.edges[node.name][node.index][p_name]:\n",
    "            edge = exp.corr.edges[node.name][node.index][p_name][p_idx]\n",
    "            remove_edges.append((node.name, node.index, p_name, p_idx))\n",
    "            edge.present = False\n",
    "    for n_name, n_idx, p_name, p_idx in remove_edges:\n",
    "        #print(f'\\t Removing edge {p_name}, {p_idx} <-> {n_name}, {n_idx}')\n",
    "        exp.corr.remove_edge(\n",
    "            n_name, n_idx, p_name, p_idx\n",
    "        )\n",
    "    # Removing all outgoing edges from the node using BFS\n",
    "    remove_redundant_node(exp, node, safe=False)\n",
    "\n",
    "def find_attn_node(exp, layer, head):\n",
    "    return exp.corr.graph[f'blocks.{layer}.attn.hook_result'][TorchIndex([None, None, head])]\n",
    "\n",
    "def find_attn_node_qkv(exp, layer, head):\n",
    "    nodes = []\n",
    "    for qkv in ['q', 'k', 'v']:\n",
    "        nodes.append(exp.corr.graph[f'blocks.{layer}.attn.hook_{qkv}'][TorchIndex([None, None, head])])\n",
    "        nodes.append(exp.corr.graph[f'blocks.{layer}.hook_{qkv}_input'][TorchIndex([None, None, head])])\n",
    "    return nodes\n",
    "    \n",
    "def split_layers_and_heads(act: Tensor, model: HookedTransformer) -> Tensor:\n",
    "    return einops.rearrange(act, '(layer head) batch seq d_model -> layer head batch seq d_model',\n",
    "                            layer=model.cfg.n_layers,\n",
    "                            head=model.cfg.n_heads)\n",
    "\n",
    "hook_filter = lambda name: name.endswith(\"ln1.hook_normalized\") or name.endswith(\"attn.hook_result\")\n",
    "def get_3_caches(model, clean_input, corrupted_input, metric):\n",
    "    # cache the activations and gradients of the clean inputs\n",
    "    model.reset_hooks()\n",
    "    clean_cache = {}\n",
    "\n",
    "    def forward_cache_hook(act, hook):\n",
    "        clean_cache[hook.name] = act.detach()\n",
    "\n",
    "    model.add_hook(hook_filter, forward_cache_hook, \"fwd\")\n",
    "\n",
    "    clean_grad_cache = {}\n",
    "\n",
    "    def backward_cache_hook(act, hook):\n",
    "        clean_grad_cache[hook.name] = act.detach()\n",
    "\n",
    "    model.add_hook(hook_filter, backward_cache_hook, \"bwd\")\n",
    "\n",
    "    value = metric(model(clean_input))\n",
    "    value.backward()\n",
    "\n",
    "    # cache the activations of the corrupted inputs\n",
    "    model.reset_hooks()\n",
    "    corrupted_cache = {}\n",
    "\n",
    "    def forward_cache_hook(act, hook):\n",
    "        corrupted_cache[hook.name] = act.detach()\n",
    "\n",
    "    model.add_hook(hook_filter, forward_cache_hook, \"fwd\")\n",
    "    model(corrupted_input)\n",
    "    model.reset_hooks()\n",
    "\n",
    "    clean_cache = ActivationCache(clean_cache, model)\n",
    "    corrupted_cache = ActivationCache(corrupted_cache, model)\n",
    "    clean_grad_cache = ActivationCache(clean_grad_cache, model)\n",
    "    return clean_cache, corrupted_cache, clean_grad_cache\n",
    "\n",
    "def get_nodes(correspondence):\n",
    "    nodes = set()\n",
    "    for child_hook_name in correspondence.edges:\n",
    "        for child_index in correspondence.edges[child_hook_name]:\n",
    "            for parent_hook_name in correspondence.edges[child_hook_name][child_index]:\n",
    "                for parent_index in correspondence.edges[child_hook_name][child_index][parent_hook_name]:\n",
    "                    edge = correspondence.edges[child_hook_name][child_index][parent_hook_name][parent_index]\n",
    "\n",
    "                    parent = correspondence.graph[parent_hook_name][parent_index]\n",
    "                    child = correspondence.graph[child_hook_name][child_index]\n",
    "\n",
    "                    parent_name = get_node_name(parent, show_full_index=False)\n",
    "                    child_name = get_node_name(child, show_full_index=False)\n",
    "                    \n",
    "                    if any(qkv in child_name or qkv in parent_name for qkv in ['_q_', '_k_', '_v_']):\n",
    "                        continue\n",
    "                    parent_name = parent_name.replace(\"_q>\", \">\").replace(\"_k>\", \">\").replace(\"_v>\", \">\")\n",
    "                    child_name = child_name.replace(\"_q>\", \">\").replace(\"_k>\", \">\").replace(\"_v>\", \">\")\n",
    "\n",
    "                    if parent_name == child_name:\n",
    "                        # Important this go after the qkv removal\n",
    "                        continue\n",
    "                    \n",
    "                    if edge.present and edge.edge_type != EdgeType.PLACEHOLDER:\n",
    "                        #print(f'Edge from {parent_name=} to {child_name=}')\n",
    "                        for node_name in [parent_name, child_name]:\n",
    "                            nodes.add(node_name)\n",
    "    return nodes\n",
    "\n",
    "def acdc_nodes(model: HookedTransformer,\n",
    "              clean_input: Tensor,\n",
    "              corrupted_input: Tensor,\n",
    "              metric: Callable[[Tensor], Tensor],\n",
    "              threshold: float,\n",
    "              exp: TLACDCExperiment,\n",
    "              attr_absolute_val: bool = False) -> Tuple[\n",
    "                  HookedTransformer, Bool[Tensor, 'n_layer n_heads']]:\n",
    "    '''\n",
    "    Runs attribution-patching-based ACDC on the model, using the given metric and data.\n",
    "    Returns the pruned model, and which heads were pruned.\n",
    "\n",
    "    Arguments:\n",
    "        model: the model to prune\n",
    "        clean_input: the input to the model that contains should elicit the behavior we're looking for\n",
    "        corrupted_input: the input to the model that should elicit random behavior\n",
    "        metric: the metric to use to compare the model's performance on the clean and corrupted inputs\n",
    "        threshold: the threshold below which to prune\n",
    "        create_model: a function that returns a new model of the same type as the input model\n",
    "        attr_absolute_val: whether to take the absolute value of the attribution before thresholding\n",
    "    '''\n",
    "    # get the 2 fwd and 1 bwd caches; cache \"normalized\" and \"result\" of attn layers\n",
    "    clean_cache, corrupted_cache, clean_grad_cache = get_3_caches(model, clean_input, corrupted_input, metric)\n",
    "\n",
    "    # compute first-order Taylor approximation for each node to get the attribution\n",
    "    clean_head_act = clean_cache.stack_head_results()\n",
    "    corr_head_act = corrupted_cache.stack_head_results()\n",
    "    clean_grad_act = clean_grad_cache.stack_head_results()\n",
    "\n",
    "    # compute attributions of each node\n",
    "    node_attr = (clean_head_act - corr_head_act) * clean_grad_act\n",
    "    # separate layers and heads, sum over d_model (to complete the dot product), batch, and seq\n",
    "    node_attr = split_layers_and_heads(node_attr, model).sum((2, 3, 4))\n",
    "\n",
    "    if attr_absolute_val:\n",
    "        node_attr = node_attr.abs()\n",
    "    del clean_cache\n",
    "    del clean_head_act\n",
    "    del corrupted_cache\n",
    "    del corr_head_act\n",
    "    del clean_grad_cache\n",
    "    del clean_grad_act\n",
    "    t.cuda.empty_cache()\n",
    "    # prune all nodes whose attribution is below the threshold\n",
    "    should_prune = node_attr < threshold\n",
    "    pruned_nodes_attr = {}\n",
    "    for layer, head in itertools.product(range(model.cfg.n_layers), range(model.cfg.n_heads)):\n",
    "        if should_prune[layer, head]:\n",
    "            # REMOVING NODE\n",
    "            print(f'PRUNING L{layer}H{head} with attribution {node_attr[layer, head]}')\n",
    "            # Find the corresponding node in computation graph\n",
    "            node = find_attn_node(exp, layer, head)\n",
    "            print(f'\\tFound node {node.name}')\n",
    "            # Prune node\n",
    "            remove_node(exp, node)\n",
    "            print(f'\\tRemoved node {node.name}')\n",
    "            pruned_nodes_attr[(layer, head)] = node_attr[layer, head]\n",
    "            \n",
    "            # REMOVING QKV\n",
    "            qkv_nodes = find_attn_node_qkv(exp, layer, head)\n",
    "            for node in qkv_nodes:\n",
    "                remove_node(exp, node)\n",
    "    return pruned_nodes_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('Automatic-Circuit-Discovery/')\n",
    "sys.path.append('utils/')\n",
    "import re\n",
    "\n",
    "import acdc\n",
    "from acdc.TLACDCExperiment import TLACDCExperiment\n",
    "from acdc.acdc_utils import TorchIndex, EdgeType\n",
    "import numpy as np\n",
    "import torch as t\n",
    "from torch import Tensor\n",
    "import einops\n",
    "import itertools\n",
    "\n",
    "from transformer_lens import HookedTransformer, ActivationCache\n",
    "\n",
    "import tqdm.notebook as tqdm\n",
    "import plotly\n",
    "from rich import print as rprint\n",
    "from rich.table import Table\n",
    "\n",
    "from jaxtyping import Float, Bool\n",
    "from typing import Callable, Tuple, Union, Dict, Optional\n",
    "\n",
    "# ACDCpp helpers\n",
    "# from utils.prune_utils import get_nodes, acdc_nodes\n",
    "# from utils.graphics_utils import show\n",
    "\n",
    "\n",
    "device = t.device('cuda') if t.cuda.is_available() else t.device('cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\n",
    "    'gpt2-small',\n",
    "    center_writing_weights=False,\n",
    "    center_unembed=False,\n",
    "    fold_ln=False,\n",
    "    device=device,\n",
    ")\n",
    "model.set_use_hook_mlp_in(True)\n",
    "model.set_use_split_qkv_input(True)\n",
    "model.set_use_attn_result(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The demonstrations lasted from the year 1145 to 11',\n",
       " 'The assaults lasted from the year 1684 to 16',\n",
       " 'The affair lasted from the year 1222 to 12',\n",
       " 'The stature lasted from the year 1784 to 17',\n",
       " 'The effort lasted from the year 1630 to 16',\n",
       " 'The experiments lasted from the year 1477 to 14',\n",
       " 'The employment lasted from the year 1286 to 12',\n",
       " 'The hostility lasted from the year 1645 to 16',\n",
       " 'The collaboration lasted from the year 1557 to 15',\n",
       " 'The competition lasted from the year 1454 to 14',\n",
       " 'The plan lasted from the year 1651 to 16',\n",
       " 'The negotiation lasted from the year 1247 to 12',\n",
       " 'The endeavor lasted from the year 1739 to 17',\n",
       " 'The expansion lasted from the year 1733 to 17',\n",
       " 'The relationship lasted from the year 1184 to 11',\n",
       " 'The challenge lasted from the year 1136 to 11',\n",
       " 'The evaluation lasted from the year 1780 to 17',\n",
       " 'The tests lasted from the year 1429 to 14',\n",
       " 'The slump lasted from the year 1214 to 12',\n",
       " 'The existence lasted from the year 1181 to 11',\n",
       " 'The challenge lasted from the year 1328 to 13',\n",
       " 'The riot lasted from the year 1175 to 11',\n",
       " 'The attempts lasted from the year 1470 to 14',\n",
       " 'The slump lasted from the year 1751 to 17',\n",
       " 'The employment lasted from the year 1246 to 12']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from acdc.greaterthan.utils import get_year_data\n",
    "N=25\n",
    "\n",
    "dataset = get_year_data(N, model)\n",
    "dataset[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from acdc.greaterthan.utils import greaterthan_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.7149)\n"
     ]
    }
   ],
   "source": [
    "with t.no_grad():\n",
    "    sample_prompt_tokens = dataset[0][0].unsqueeze(0)\n",
    "    logits = model(sample_prompt_tokens)\n",
    "    print(greaterthan_metric(logits, sample_prompt_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACDC++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:cache_all is deprecated and will eventually be removed, use add_caching_hooks or run_with_cache\n",
      "WARNING:root:cache_all is deprecated and will eventually be removed, use add_caching_hooks or run_with_cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln_final.hook_normalized\n",
      "ln_final.hook_scale\n",
      "blocks.11.hook_resid_post\n",
      "blocks.11.hook_mlp_out\n",
      "blocks.11.mlp.hook_post\n",
      "blocks.11.mlp.hook_pre\n",
      "blocks.11.ln2.hook_normalized\n",
      "blocks.11.ln2.hook_scale\n",
      "blocks.11.hook_mlp_in\n",
      "blocks.11.hook_resid_mid\n",
      "blocks.11.hook_attn_out\n",
      "blocks.11.attn.hook_result\n",
      "blocks.11.attn.hook_z\n",
      "blocks.11.attn.hook_pattern\n",
      "blocks.11.attn.hook_attn_scores\n",
      "blocks.11.attn.hook_v\n",
      "blocks.11.attn.hook_k\n",
      "blocks.11.attn.hook_q\n",
      "blocks.11.ln1.hook_normalized\n",
      "blocks.11.ln1.hook_scale\n",
      "blocks.11.hook_v_input\n",
      "blocks.11.hook_k_input\n",
      "blocks.11.hook_q_input\n",
      "blocks.11.hook_resid_pre\n",
      "blocks.10.hook_resid_post\n",
      "blocks.10.hook_mlp_out\n",
      "blocks.10.mlp.hook_post\n",
      "blocks.10.mlp.hook_pre\n",
      "blocks.10.ln2.hook_normalized\n",
      "blocks.10.ln2.hook_scale\n",
      "blocks.10.hook_mlp_in\n",
      "blocks.10.hook_resid_mid\n",
      "blocks.10.hook_attn_out\n",
      "blocks.10.attn.hook_result\n",
      "blocks.10.attn.hook_z\n",
      "blocks.10.attn.hook_pattern\n",
      "blocks.10.attn.hook_attn_scores\n",
      "blocks.10.attn.hook_v\n",
      "blocks.10.attn.hook_k\n",
      "blocks.10.attn.hook_q\n",
      "blocks.10.ln1.hook_normalized\n",
      "blocks.10.ln1.hook_scale\n",
      "blocks.10.hook_v_input\n",
      "blocks.10.hook_k_input\n",
      "blocks.10.hook_q_input\n",
      "blocks.10.hook_resid_pre\n",
      "blocks.9.hook_resid_post\n",
      "blocks.9.hook_mlp_out\n",
      "blocks.9.mlp.hook_post\n",
      "blocks.9.mlp.hook_pre\n",
      "blocks.9.ln2.hook_normalized\n",
      "blocks.9.ln2.hook_scale\n",
      "blocks.9.hook_mlp_in\n",
      "blocks.9.hook_resid_mid\n",
      "blocks.9.hook_attn_out\n",
      "blocks.9.attn.hook_result\n",
      "blocks.9.attn.hook_z\n",
      "blocks.9.attn.hook_pattern\n",
      "blocks.9.attn.hook_attn_scores\n",
      "blocks.9.attn.hook_v\n",
      "blocks.9.attn.hook_k\n",
      "blocks.9.attn.hook_q\n",
      "blocks.9.ln1.hook_normalized\n",
      "blocks.9.ln1.hook_scale\n",
      "blocks.9.hook_v_input\n",
      "blocks.9.hook_k_input\n",
      "blocks.9.hook_q_input\n",
      "blocks.9.hook_resid_pre\n",
      "blocks.8.hook_resid_post\n",
      "blocks.8.hook_mlp_out\n",
      "blocks.8.mlp.hook_post\n",
      "blocks.8.mlp.hook_pre\n",
      "blocks.8.ln2.hook_normalized\n",
      "blocks.8.ln2.hook_scale\n",
      "blocks.8.hook_mlp_in\n",
      "blocks.8.hook_resid_mid\n",
      "blocks.8.hook_attn_out\n",
      "blocks.8.attn.hook_result\n",
      "blocks.8.attn.hook_z\n",
      "blocks.8.attn.hook_pattern\n",
      "blocks.8.attn.hook_attn_scores\n",
      "blocks.8.attn.hook_v\n",
      "blocks.8.attn.hook_k\n",
      "blocks.8.attn.hook_q\n",
      "blocks.8.ln1.hook_normalized\n",
      "blocks.8.ln1.hook_scale\n",
      "blocks.8.hook_v_input\n",
      "blocks.8.hook_k_input\n",
      "blocks.8.hook_q_input\n",
      "blocks.8.hook_resid_pre\n",
      "blocks.7.hook_resid_post\n",
      "blocks.7.hook_mlp_out\n",
      "blocks.7.mlp.hook_post\n",
      "blocks.7.mlp.hook_pre\n",
      "blocks.7.ln2.hook_normalized\n",
      "blocks.7.ln2.hook_scale\n",
      "blocks.7.hook_mlp_in\n",
      "blocks.7.hook_resid_mid\n",
      "blocks.7.hook_attn_out\n",
      "blocks.7.attn.hook_result\n",
      "blocks.7.attn.hook_z\n",
      "blocks.7.attn.hook_pattern\n",
      "blocks.7.attn.hook_attn_scores\n",
      "blocks.7.attn.hook_v\n",
      "blocks.7.attn.hook_k\n",
      "blocks.7.attn.hook_q\n",
      "blocks.7.ln1.hook_normalized\n",
      "blocks.7.ln1.hook_scale\n",
      "blocks.7.hook_v_input\n",
      "blocks.7.hook_k_input\n",
      "blocks.7.hook_q_input\n",
      "blocks.7.hook_resid_pre\n",
      "blocks.6.hook_resid_post\n",
      "blocks.6.hook_mlp_out\n",
      "blocks.6.mlp.hook_post\n",
      "blocks.6.mlp.hook_pre\n",
      "blocks.6.ln2.hook_normalized\n",
      "blocks.6.ln2.hook_scale\n",
      "blocks.6.hook_mlp_in\n",
      "blocks.6.hook_resid_mid\n",
      "blocks.6.hook_attn_out\n",
      "blocks.6.attn.hook_result\n",
      "blocks.6.attn.hook_z\n",
      "blocks.6.attn.hook_pattern\n",
      "blocks.6.attn.hook_attn_scores\n",
      "blocks.6.attn.hook_v\n",
      "blocks.6.attn.hook_k\n",
      "blocks.6.attn.hook_q\n",
      "blocks.6.ln1.hook_normalized\n",
      "blocks.6.ln1.hook_scale\n",
      "blocks.6.hook_v_input\n",
      "blocks.6.hook_k_input\n",
      "blocks.6.hook_q_input\n",
      "blocks.6.hook_resid_pre\n",
      "blocks.5.hook_resid_post\n",
      "blocks.5.hook_mlp_out\n",
      "blocks.5.mlp.hook_post\n",
      "blocks.5.mlp.hook_pre\n",
      "blocks.5.ln2.hook_normalized\n",
      "blocks.5.ln2.hook_scale\n",
      "blocks.5.hook_mlp_in\n",
      "blocks.5.hook_resid_mid\n",
      "blocks.5.hook_attn_out\n",
      "blocks.5.attn.hook_result\n",
      "blocks.5.attn.hook_z\n",
      "blocks.5.attn.hook_pattern\n",
      "blocks.5.attn.hook_attn_scores\n",
      "blocks.5.attn.hook_v\n",
      "blocks.5.attn.hook_k\n",
      "blocks.5.attn.hook_q\n",
      "blocks.5.ln1.hook_normalized\n",
      "blocks.5.ln1.hook_scale\n",
      "blocks.5.hook_v_input\n",
      "blocks.5.hook_k_input\n",
      "blocks.5.hook_q_input\n",
      "blocks.5.hook_resid_pre\n",
      "blocks.4.hook_resid_post\n",
      "blocks.4.hook_mlp_out\n",
      "blocks.4.mlp.hook_post\n",
      "blocks.4.mlp.hook_pre\n",
      "blocks.4.ln2.hook_normalized\n",
      "blocks.4.ln2.hook_scale\n",
      "blocks.4.hook_mlp_in\n",
      "blocks.4.hook_resid_mid\n",
      "blocks.4.hook_attn_out\n",
      "blocks.4.attn.hook_result\n",
      "blocks.4.attn.hook_z\n",
      "blocks.4.attn.hook_pattern\n",
      "blocks.4.attn.hook_attn_scores\n",
      "blocks.4.attn.hook_v\n",
      "blocks.4.attn.hook_k\n",
      "blocks.4.attn.hook_q\n",
      "blocks.4.ln1.hook_normalized\n",
      "blocks.4.ln1.hook_scale\n",
      "blocks.4.hook_v_input\n",
      "blocks.4.hook_k_input\n",
      "blocks.4.hook_q_input\n",
      "blocks.4.hook_resid_pre\n",
      "blocks.3.hook_resid_post\n",
      "blocks.3.hook_mlp_out\n",
      "blocks.3.mlp.hook_post\n",
      "blocks.3.mlp.hook_pre\n",
      "blocks.3.ln2.hook_normalized\n",
      "blocks.3.ln2.hook_scale\n",
      "blocks.3.hook_mlp_in\n",
      "blocks.3.hook_resid_mid\n",
      "blocks.3.hook_attn_out\n",
      "blocks.3.attn.hook_result\n",
      "blocks.3.attn.hook_z\n",
      "blocks.3.attn.hook_pattern\n",
      "blocks.3.attn.hook_attn_scores\n",
      "blocks.3.attn.hook_v\n",
      "blocks.3.attn.hook_k\n",
      "blocks.3.attn.hook_q\n",
      "blocks.3.ln1.hook_normalized\n",
      "blocks.3.ln1.hook_scale\n",
      "blocks.3.hook_v_input\n",
      "blocks.3.hook_k_input\n",
      "blocks.3.hook_q_input\n",
      "blocks.3.hook_resid_pre\n",
      "blocks.2.hook_resid_post\n",
      "blocks.2.hook_mlp_out\n",
      "blocks.2.mlp.hook_post\n",
      "blocks.2.mlp.hook_pre\n",
      "blocks.2.ln2.hook_normalized\n",
      "blocks.2.ln2.hook_scale\n",
      "blocks.2.hook_mlp_in\n",
      "blocks.2.hook_resid_mid\n",
      "blocks.2.hook_attn_out\n",
      "blocks.2.attn.hook_result\n",
      "blocks.2.attn.hook_z\n",
      "blocks.2.attn.hook_pattern\n",
      "blocks.2.attn.hook_attn_scores\n",
      "blocks.2.attn.hook_v\n",
      "blocks.2.attn.hook_k\n",
      "blocks.2.attn.hook_q\n",
      "blocks.2.ln1.hook_normalized\n",
      "blocks.2.ln1.hook_scale\n",
      "blocks.2.hook_v_input\n",
      "blocks.2.hook_k_input\n",
      "blocks.2.hook_q_input\n",
      "blocks.2.hook_resid_pre\n",
      "blocks.1.hook_resid_post\n",
      "blocks.1.hook_mlp_out\n",
      "blocks.1.mlp.hook_post\n",
      "blocks.1.mlp.hook_pre\n",
      "blocks.1.ln2.hook_normalized\n",
      "blocks.1.ln2.hook_scale\n",
      "blocks.1.hook_mlp_in\n",
      "blocks.1.hook_resid_mid\n",
      "blocks.1.hook_attn_out\n",
      "blocks.1.attn.hook_result\n",
      "blocks.1.attn.hook_z\n",
      "blocks.1.attn.hook_pattern\n",
      "blocks.1.attn.hook_attn_scores\n",
      "blocks.1.attn.hook_v\n",
      "blocks.1.attn.hook_k\n",
      "blocks.1.attn.hook_q\n",
      "blocks.1.ln1.hook_normalized\n",
      "blocks.1.ln1.hook_scale\n",
      "blocks.1.hook_v_input\n",
      "blocks.1.hook_k_input\n",
      "blocks.1.hook_q_input\n",
      "blocks.1.hook_resid_pre\n",
      "blocks.0.hook_resid_post\n",
      "blocks.0.hook_mlp_out\n",
      "blocks.0.mlp.hook_post\n",
      "blocks.0.mlp.hook_pre\n",
      "blocks.0.ln2.hook_normalized\n",
      "blocks.0.ln2.hook_scale\n",
      "blocks.0.hook_mlp_in\n",
      "blocks.0.hook_resid_mid\n",
      "blocks.0.hook_attn_out\n",
      "blocks.0.attn.hook_result\n",
      "blocks.0.attn.hook_z\n",
      "blocks.0.attn.hook_pattern\n",
      "blocks.0.attn.hook_attn_scores\n",
      "blocks.0.attn.hook_v\n",
      "blocks.0.attn.hook_k\n",
      "blocks.0.attn.hook_q\n",
      "blocks.0.ln1.hook_normalized\n",
      "blocks.0.ln1.hook_scale\n",
      "blocks.0.hook_v_input\n",
      "blocks.0.hook_k_input\n",
      "blocks.0.hook_q_input\n",
      "blocks.0.hook_resid_pre\n",
      "hook_pos_embed\n",
      "hook_embed\n",
      "self.current_node=TLACDCInterpNode(blocks.11.hook_resid_post, [:])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "greaterthan_metric() missing 1 required positional argument: 'tokens'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m start_thresh_time \u001b[39m=\u001b[39m time()\n\u001b[1;32m     10\u001b[0m \u001b[39m# Set up model\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m# Set up experiment\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m exp \u001b[39m=\u001b[39m TLACDCExperiment(\n\u001b[1;32m     13\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m     14\u001b[0m     threshold\u001b[39m=\u001b[39;49mthreshold,\n\u001b[1;32m     15\u001b[0m     run_name\u001b[39m=\u001b[39;49mrun_name,\n\u001b[1;32m     16\u001b[0m     ds\u001b[39m=\u001b[39;49mdataset[\u001b[39m0\u001b[39;49m],\n\u001b[1;32m     17\u001b[0m     ref_ds\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     18\u001b[0m     metric\u001b[39m=\u001b[39;49mgreaterthan_metric,\n\u001b[1;32m     19\u001b[0m     zero_ablation\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     20\u001b[0m     hook_verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mSetting up graph\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[39m# Set up computational graph\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/acdc_env/envs/acdcpp_env/lib/python3.10/site-packages/acdc/TLACDCExperiment.py:164\u001b[0m, in \u001b[0;36mTLACDCExperiment.__init__\u001b[0;34m(self, model, ds, ref_ds, threshold, metric, run_name, second_metric, verbose, hook_verbose, parallel_hypotheses, remove_redundant, online_cache_cpu, corrupted_cache_cpu, zero_ablation, abs_value_threshold, show_full_index, using_wandb, wandb_entity_name, wandb_project_name, wandb_run_name, wandb_group_name, wandb_notes, wandb_dir, wandb_mode, use_pos_embed, skip_edges, add_sender_hooks, add_receiver_hooks, indices_mode, names_mode, wandb_config, early_exit)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetric \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: metric(x)\u001b[39m.\u001b[39mitem()\n\u001b[1;32m    163\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msecond_metric \u001b[39m=\u001b[39m second_metric\n\u001b[0;32m--> 164\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate_cur_metric()\n\u001b[1;32m    166\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mthreshold \u001b[39m=\u001b[39m threshold\n\u001b[1;32m    167\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_passes \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/acdc_env/envs/acdcpp_env/lib/python3.10/site-packages/acdc/TLACDCExperiment.py:199\u001b[0m, in \u001b[0;36mTLACDCExperiment.update_cur_metric\u001b[0;34m(self, recalc_metric, recalc_edges, initial)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mif\u001b[39;00m recalc_metric:\n\u001b[1;32m    198\u001b[0m     logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mds)\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcur_metric \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmetric(logits)\n\u001b[1;32m    200\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msecond_metric \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcur_second_metric \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msecond_metric(logits)\n",
      "File \u001b[0;32m~/.pyenv/versions/acdc_env/envs/acdcpp_env/lib/python3.10/site-packages/acdc/TLACDCExperiment.py:162\u001b[0m, in \u001b[0;36mTLACDCExperiment.__init__.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39mif\u001b[39;00m using_wandb:\n\u001b[1;32m    151\u001b[0m     wandb\u001b[39m.\u001b[39minit(\n\u001b[1;32m    152\u001b[0m         entity\u001b[39m=\u001b[39mwandb_entity_name,\n\u001b[1;32m    153\u001b[0m         group\u001b[39m=\u001b[39mwandb_group_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m         config\u001b[39m=\u001b[39mwandb_config,\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 162\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetric \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: metric(x)\u001b[39m.\u001b[39mitem()\n\u001b[1;32m    163\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msecond_metric \u001b[39m=\u001b[39m second_metric\n\u001b[1;32m    164\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_cur_metric()\n",
      "\u001b[0;31mTypeError\u001b[0m: greaterthan_metric() missing 1 required positional argument: 'tokens'"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "THRESHOLDS = [0.005, 0.01, 0.015, 0.02, 0.025]\n",
    "run_name = 'greaterthan_thresh_run'\n",
    "pruned_nodes_per_thresh = {}\n",
    "num_forward_passes_per_thresh = {}\n",
    "heads_per_thresh = {}\n",
    "os.makedirs(f'./greaterthan_ims/{run_name}', exist_ok=True)\n",
    "for threshold in THRESHOLDS:\n",
    "    start_thresh_time = time()\n",
    "    # Set up model\n",
    "    # Set up experiment\n",
    "    exp = TLACDCExperiment(\n",
    "        model=model,\n",
    "        threshold=threshold,\n",
    "        run_name=run_name,\n",
    "        ds=dataset[0],\n",
    "        ref_ds=None,\n",
    "        metric=greaterthan_metric,\n",
    "        zero_ablation=True,\n",
    "        hook_verbose=False\n",
    "    )\n",
    "    print('Setting up graph')\n",
    "    # Set up computational graph\n",
    "    exp.model.reset_hooks()\n",
    "    exp.setup_model_hooks(\n",
    "        add_sender_hooks=True,\n",
    "        add_receiver_hooks=True,\n",
    "        doing_acdc_runs=False,\n",
    "    )\n",
    "    exp_time = time()\n",
    "    print(f'Time to set up exp: {exp_time - start_thresh_time}')\n",
    "    for _ in range(10):\n",
    "        pruned_nodes_attr = acdc_nodes(\n",
    "            model=exp.model,\n",
    "            clean_input=dataset[0],\n",
    "            corrupted_input=dataset[0],\n",
    "            metric=greaterthan_metric,\n",
    "            threshold=threshold,\n",
    "            exp=exp,\n",
    "            attr_absolute_val=True,\n",
    "        ) \n",
    "        t.cuda.empty_cache()\n",
    "    acdcpp_time = time()\n",
    "    print(f'ACDC++ time: {acdcpp_time - exp_time}')\n",
    "    heads_per_thresh[threshold] = [get_nodes(exp.corr)]\n",
    "    pruned_nodes_per_thresh[threshold] = pruned_nodes_attr\n",
    "    show(exp.corr, fname=f'ims/{run_name}/thresh{threshold}_before_acdc.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acdcpp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
