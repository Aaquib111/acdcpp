{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6606875e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../Automatic-Circuit-Discovery/')\n",
    "sys.path.append('..')\n",
    "\n",
    "from acdc.greaterthan.utils import get_all_greaterthan_things\n",
    "from ACDCPPExperiment import ACDCPPExperiment\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "import numpy as np\n",
    "import torch as t\n",
    "import tqdm.notebook as tqdm\n",
    "import json\n",
    "\n",
    "device = t.device('cuda') if t.cuda.is_available() else t.device('cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a16eab",
   "metadata": {},
   "source": [
    "# Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20df2bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HookedTransformer.from_pretrained(\n",
    "    'gpt2-small',\n",
    "    center_writing_weights=False,\n",
    "    center_unembed=False,\n",
    "    fold_ln=False,\n",
    "    device=device,\n",
    ")\n",
    "model.set_use_hook_mlp_in(True)\n",
    "model.set_use_split_qkv_input(True)\n",
    "model.set_use_attn_result(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292dfbf6",
   "metadata": {},
   "source": [
    "# Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601a7d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make clean dataset and reference dataset\n",
    "N = 25\n",
    "\n",
    "things = get_all_greaterthan_things(\n",
    "    num_examples=N, metric_name=\"greaterthan\", device=device\n",
    ")\n",
    "greaterthan_metric = things.validation_metric\n",
    "toks_int_values = things.validation_data # clean data x_i\n",
    "toks_int_values_other = things.validation_patch_data # corrupted data x_i'\n",
    "\n",
    "print(\"\\nClean dataset samples\")\n",
    "for i in range(5):\n",
    "    print(model.tokenizer.decode(toks_int_values[i]))\n",
    "\n",
    "print(\"\\nReference dataset samples\")\n",
    "for i in range(5):\n",
    "    print(model.tokenizer.decode(toks_int_values_other[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf81ab6e",
   "metadata": {},
   "source": [
    "# Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b08e9e-a140-4a97-a309-3210cc8f8ff3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ACDCPPExperiment import ACDCPPExperiment\n",
    "import numpy as np\n",
    "THRESHOLDS = np.logspace(-4, 1, num=20, base=5)\n",
    "# I'm just using one threshold so I can move fast!\n",
    "\n",
    "tl_model.reset_hooks()\n",
    "RUN_NAME = 'acdcpp_edges'\n",
    "acdcpp_exp = ACDCPPExperiment(\n",
    "    model=tl_model,\n",
    "    clean_data=test_data,\n",
    "    corr_data=test_patch_data,\n",
    "    acdc_metric=neg_abs_docstring_metric,\n",
    "    acdcpp_metric=test_metrics['docstring_metric'],\n",
    "    thresholds=THRESHOLDS,\n",
    "    run_name=RUN_NAME,\n",
    "    verbose=False,\n",
    "    attr_absolute_val=True,\n",
    "    save_graphs_after=0,\n",
    "    run_acdcpp=True,\n",
    "    run_acdc=False,\n",
    "    pruning_mode='edge',\n",
    "    no_pruned_nodes_attr=1,\n",
    ")\n",
    "\n",
    "pruned_heads, num_passes, acdcpp_pruned_attrs, acdc_pruned_attrs, edges_after_acdcpp, edges_after_acdc = acdcpp_exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c0b5e5-7732-42da-b92e-687536aca96c",
   "metadata": {},
   "source": [
    "# Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fdca38-9c1a-45ee-8625-93c06b569533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_torch_index(index_list):\n",
    "    return ''.join(['None' if i == ':' else i for i in index_list])\n",
    "\n",
    "for thresh in pruned_heads.keys():\n",
    "    pruned_heads[thresh][0] = list(pruned_heads[thresh][0])\n",
    "    pruned_heads[thresh][1] = list(pruned_heads[thresh][1])\n",
    "\n",
    "cleaned_attrs = {}\n",
    "for thresh in pruned_attrs.keys():\n",
    "    cleaned_attrs[thresh] = []\n",
    "    for ((e1, i1), (e2, i2)), attr in pruned_attrs[thresh].items():\n",
    "        cleaned_attrs[thresh].append([e1, convert_to_torch_index(str(i1)), e2, convert_to_torch_index(str(i2)), attr])\n",
    "        \n",
    "with open(f'{RUN_NAME}_pruned_heads.json', 'w') as f:\n",
    "    json.dump(pruned_heads, f)\n",
    "with open(f'{RUN_NAME}_num_passes.json', 'w') as f:\n",
    "    json.dump(num_passes, f)\n",
    "with open(f'{RUN_NAME}_pruned_attrs.json', 'w') as f:\n",
    "    json.dump(cleaned_attrs, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
